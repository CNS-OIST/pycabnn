{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BREPpy sandbox\n",
    "\n",
    "\n",
    "**So far:**\n",
    "- Generate the cell-representing dots\n",
    "- Implement knn-search\n",
    "    - (Optimize speed -> Parallelize!)\n",
    "- Write tests (General correct function, Comparison with scheme-BREP)\n",
    "\n",
    "**Open questions:**\n",
    "- How was the spacing \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the Parameter file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not nice: there are about 4 different names for one variable- there are the default ones in the code, the assigned ones in the code, and the ones in the parameter file. \n",
    "I will use variables that are similar to the ones defined in the grammar in the code, with the difference that they will be adapted to Python syntax ( _ instead of -), and a few have an additional postfix to clarify what they do (e.g. \\_fn = filename) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On the installation of neuron\n",
    "Neuron did not really work out of the box for me. \n",
    "I (ubuntu 16.04 LTS, 64 bit) did it the following way:\n",
    "- Download the .rpm package from here: https://www.neuron.yale.edu/neuron/download\n",
    "- Install it with: \n",
    "    `alien -i nrn_...*package*` (Note that the .deb package did not work out, and neither did the installation using rpm directly)\n",
    "- Edit the .bashrc file by adding the following lines: \n",
    "\n",
    "    `#Added for neuron\n",
    "    export PYTHONPATH=\"${PYTHONPATH}:/usr/local/nrn/lib/python/\" `\n",
    "    \n",
    "    (first check that this path is actually where it got installed by going to the folder and see whether `python -c 'import neuron'` tells you about your NEURON version or whether there ain't no module called neuron.\n",
    "\n",
    "\n",
    "http://www.davison.webfactional.com/notes/hoc-to-python-bulbnet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T16:34:52.690809Z",
     "start_time": "2017-11-10T16:34:49.289096Z"
    },
    "collapsed": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pickle \n",
    "import warnings\n",
    "import neuron\n",
    "import sys\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "#! echo $PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T16:49:33.756825Z",
     "start_time": "2017-11-10T16:49:33.520351Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.99000000e+02   1.00000000e+00   8.70000000e+01]\n",
      " [  1.13800000e+03   5.70000000e+02   1.22000000e+02]\n",
      " [  1.01200000e+03   6.50000000e+01   1.45000000e+02]\n",
      " ..., \n",
      " [  5.96000000e+02   3.20000000e+01   8.00000000e+01]\n",
      " [  1.18000000e+03   6.97000000e+02   1.35000000e+02]\n",
      " [  1.39500000e+03   4.45000000e+02   8.30000000e+01]]\n",
      "[array([[ 1395.        ,   445.        ,    83.        ],\n",
      "       [ 1411.65772178,   473.87267595,   116.33333333],\n",
      "       [ 1428.31544356,   502.74535189,   149.66666667],\n",
      "       [ 1444.97316534,   531.61802784,   183.        ]]), array([[ 1395.        ,   445.        ,    83.        ],\n",
      "       [ 1424.0244592 ,   461.39182355,   116.33333333],\n",
      "       [ 1453.0489184 ,   477.7836471 ,   149.66666667],\n",
      "       [ 1482.0733776 ,   494.17547064,   183.        ]])]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-303ee1a0fe37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_somata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_dendrites\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ines/Desktop/LabRot_OIST/pybrep/BREPpy.py\u001b[0m in \u001b[0;36madd_dendrites\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ma_dend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m         \u001b[0mall_dends\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconc_ab\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ma_dend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_dend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m         \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mall_dends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;31m#all_idx =\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ines/Desktop/LabRot_OIST/pybrep/BREPpy.py\u001b[0m in \u001b[0;36mconc_ab\u001b[1;34m(a, b)\u001b[0m\n\u001b[0;32m    346\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mflatten_cells\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mdat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflatten_cells\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflatten_cells\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ma_dend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ines/Desktop/LabRot_OIST/pybrep/BREPpy.py\u001b[0m in \u001b[0;36mflatten_cells\u001b[1;34m(dat)\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mconc_ab\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mflatten_cells\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 347\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mdat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    348\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflatten_cells\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflatten_cells\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "%run BREPpy.py\n",
    "\n",
    "conn = Connector()\n",
    "conn.init_from_script(['--config_fn','./input_files/Parameters.hoc', '--goc_points_fn', './dropbox_input/GoCcoordinates.dat'])\n",
    "#cp = Cell_pop (conn)\n",
    "\n",
    "#print (cp.args)\n",
    "\n",
    "gg = Golgi_pop(conn.args)\n",
    "gg.load_somata()\n",
    "print (gg.som)\n",
    "gg.add_dendrites()\n",
    "\n",
    "\n",
    "\n",
    "#gg = Golgi_pop()\n",
    "#gg.init_from_script(['--config_fn','./input_files/Parameters.hoc'])\n",
    "#gg.args.aa_goc_zone\n",
    "#Golgi_pop.check_output_prefix()\n",
    "\n",
    "#Todo: Read in from command line for int or bool parameters.\n",
    "#b = Brep()'\n",
    "#b.init_from_script(['--config_fn','./input_files/Parameters.hoc'])\n",
    "#b.read_in_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Checking out the output of the original BREP program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File read-in procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T16:34:52.719436Z",
     "start_time": "2017-11-10T16:34:52.692303Z"
    },
    "code_folding": [],
    "collapsed": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "##filenames and input paths for the different files.\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "path_4 = os.getcwd()+'/output_25/'  # 1/4 of the actual patch (each side 1/2)\n",
    "path_16 = os.getcwd()+'/output_16/' # 1/16 of actual patch\n",
    "path_full = os.getcwd()+'/output_full_def/' #output for full-sized patch, BREP default params\n",
    "path_old = os.getcwd()+'/output_1/'\n",
    "path_ivan = os.getcwd()+'/brep-ivan/'\n",
    "path_dropin = os.getcwd()+'/dropbox_input/'\n",
    "\n",
    "path = path_full\n",
    "\n",
    "fns = OrderedDict ()\n",
    "fns['aa_go_dist']='AAtoGoCdistances.dat'\n",
    "fns['aa_go_segs']='AAtoGoCsegments.dat'\n",
    "fns['aa_go_source']='AAtoGoCsources.dat'\n",
    "fns['aa_go_target']='AAtoGoCtargets.dat'\n",
    "\n",
    "fns['gran_coord'] ='GCcoordinates.sorted.dat'       \n",
    "fns['gran_t_coord']='GCTcoordinates.sorted.dat'\n",
    "    \n",
    "fns['go_coord']='GoCcoordinates.sorted.dat'\n",
    "fns['go_basd_coord']='GoCbdendcoordinates.sorted.dat'\n",
    "fns['go_apical_coord']='GoCadendcoordinates.sorted.dat'\n",
    "fns['go_axon_coord']='GoCaxoncoordinates.sorted.dat'\n",
    "fns['go_dist']='GoCdistances.dat' \n",
    "       \n",
    "fns['go_go_dist']='GoCtoGoCdistances.dat'\n",
    "fns['go_go_source']='GoCtoGoCsources.dat'\n",
    "fns['go_go_target']='GoCtoGoCtargets.dat'\n",
    "fns['go_go_gap_dist']='GoCtoGoCgapdistances.dat'\n",
    "fns['go_go_gap_source']='GoCtoGoCgapsources.dat'\n",
    "fns['go_go_gap_target']='GoCtoGoCgaptargets.dat'\n",
    "\n",
    "fns['pf_go_dist']='PFtoGoCdistances.dat'\n",
    "fns['pf_go_seg']='PFtoGoCsegments.dat'\n",
    "fns['pf_go_source']='PFtoGoCsources.dat'\n",
    "fns['pf_go_target']='PFtoGoCtargets.dat'\n",
    "\n",
    "#for k,v in fns.items():\n",
    "##    print (k)\n",
    "#a = import_csv(in_f)\n",
    "#rr = read_in_file (in_goba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T16:34:52.860559Z",
     "start_time": "2017-11-10T16:34:52.722184Z"
    },
    "code_folding": [],
    "collapsed": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def read_in_file (fn, parse_ignore = True):\n",
    "    ''' Reads in files such as the ones that BREP returns.\n",
    "    Represents lines as rows, nth element in each line as column.\n",
    "    fn = Filename\n",
    "    parse_ignore: If something cannot be parsed, it will be ignored. If this parameter is set false, it will complain\n",
    "    returns: 2d-array of floats'''\n",
    "    res = []\n",
    "    with open (fn, newline = '') as f:\n",
    "        rr = csv.reader(f, delimiter = ' ')\n",
    "        err = [] # list of elements that could not be read in\n",
    "        for line in rr: # lines -> rows\n",
    "            ar = []\n",
    "            for j in range(len(line)): \n",
    "                try: ar.append(float(line[j]))\n",
    "                except: err.append(line[j])\n",
    "            res.append(np.asarray(ar))\n",
    "    if len(err)> 0 and not parse_ignore: print ('Could not parse on {} instances: {}'.format(len(err), set(err)))\n",
    "    return np.asarray(res)\n",
    "\n",
    "\n",
    "def coord_reshape (dat, n_dim = 3):\n",
    "    ''' Reshapes coordinate files with several points in one line by adding an extra axis.\n",
    "    Thus, converts from an array with shape (#cells x (#pts*ndim)) to one with shape (#cells x #pts x ndim)'''\n",
    "    dat = dat.reshape([dat.shape[0], int(dat.shape[1]/n_dim),n_dim])\n",
    "    return dat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview over the different output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-07T13:14:08.220766Z",
     "start_time": "2017-11-07T13:13:31.734901Z"
    },
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# An overview over the different files that BREP produces and the comparison between two different files\n",
    "for k, v in fns.items():\n",
    "    print ('Read in file: ', v)\n",
    "    c_p = path+v\n",
    "    cur = read_in_file(c_p)\n",
    "    \n",
    "    #c_p2 = os.getcwd()+'/output_2/'+v\n",
    "    #cur2 = read_in_file(c_p2)\n",
    "\n",
    "    print ('Shape 1 is: ', cur.shape)\n",
    "    #print ('Shape 2 is: ', cur2.shape)\n",
    "    \n",
    "    print ('First elements in 1 are:', cur.flatten()[:15])\n",
    "    #print ('First elements in 2 are:', cur2.flatten()[:15])\n",
    "    \n",
    "    print (' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T09:35:56.205531Z",
     "start_time": "2017-11-06T09:35:56.203216Z"
    }
   },
   "source": [
    "### Connectivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T16:34:52.976471Z",
     "start_time": "2017-11-10T16:34:52.862418Z"
    },
    "collapsed": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def target_stats (dat, name = ''):\n",
    "    ''' Takes a target (or source) file, counts the number of occurences of all occurring IDs and does some statistics\n",
    "    on that (mean, std, range)\n",
    "    dat = target or source file '''\n",
    "    un, counts = np.unique(dat, return_counts=True)\n",
    "    print (name)\n",
    "    print ('Connections per cell: ', round(np.mean(counts),2),'+/-', round(np.std(counts), 2), ', range ', min(counts),'-', max(counts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = path_full\n",
    "gap_t = read_in_file(path + fns['go_go_gap_target'])\n",
    "pf_t = read_in_file(path + fns['pf_go_target'])\n",
    "aa_t = read_in_file(path+fns['aa_go_target'])\n",
    "gg_t = read_in_file(path+fns['go_go_target'])\n",
    "\n",
    "target_stats(gg_t, 'Golgi to Golgi:')\n",
    "target_stats(aa_t, 'AA to Golgi:')\n",
    "target_stats(pf_t, 'Parallel Fiber to Golgi:')\n",
    "target_stats(gap_t, 'Golgi to Golgi gap junctions:')\n",
    "\n",
    "print(\n",
    "'''\n",
    "Here are the paper values as a comparison:\n",
    "Golgi to Golgi:\n",
    "Connections per cell:  144.85 +/- 36.88 , range  72 - 195\n",
    "AA to Golgi:\n",
    "Connections per cell:  554 +/- 302 , range  55 - 1245\n",
    "Parallel Fiber to Golgi:\n",
    "Connections per cell:  4759 +/- 1037, range 2512-6582\n",
    "Golgi to Golgi gap junctions:\n",
    "Connections per cell:  13.7 +/- 4.6 , range  1-31''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Golgi-Granule interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T16:34:53.076962Z",
     "start_time": "2017-11-10T16:34:52.978260Z"
    },
    "collapsed": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def so_tar_sets (so, tar, n_so = -1, n_tar = -1):\n",
    "    '''Takes two lists of sources and targets (must have same length), and constructs a list of sets from it.\n",
    "    if n_so and n_tar are set to a positive value, empty sets will be added if necessary to reach the specified number of target/source IDs\n",
    "    Output = source-> target, target -> source'''\n",
    "    if n_so<0: n_so = int(max(so)+1)\n",
    "    if n_tar<0: n_tar = int(max(tar)+1)\n",
    "    so_tar = [set() for i in range(n_so)]\n",
    "    tar_so = [set() for i in range(n_tar)]\n",
    "    for s, t in zip (so, tar):\n",
    "        so_tar[int(s)].add(int(t))\n",
    "        tar_so[int(t)].add(int(s))\n",
    "    return so_tar, tar_so\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Go_ori = read_in_file(path+fns['go_coord']) #soma points of granule cells\n",
    "Gr_ori = read_in_file(path+fns['gran_coord']) #soma points of Golgi cells\n",
    "GrT_ori = read_in_file(path+fns['gran_t_coord'])\n",
    "pf_t = read_in_file(path+fns['pf_go_target']) #the Golgi cell ID\n",
    "pf_s = read_in_file(path+fns['pf_go_source']) #number = the parallel fiber ID\n",
    "aa_t = read_in_file(path+fns['aa_go_target'])\n",
    "aa_s = read_in_file(path+fns['aa_go_source'])\n",
    "\n",
    "\n",
    "gr_go, go_gr = so_tar_sets(pf_s, pf_t)\n",
    "\n",
    "print (gr_go[:10])\n",
    "print (go_gr[:10])\n",
    "\n",
    "ls= [len(gr_go[i]) for i in range(len(gr_go))]\n",
    "print (np.argmax(ls))\n",
    "\n",
    "ks= [len(go_gr[i]) for i in range(len(go_gr))]\n",
    "print (np.argmax(ks))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-08T15:08:12.238763Z",
     "start_time": "2017-11-08T15:07:56.974539Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#path_v = path_ivan\n",
    "#path_v = path_4\n",
    "#path_v = path_full\n",
    "path_v = path_dropin\n",
    "\n",
    "gr_iv = read_in_file(path_v + 'GCcoordinates.dat')\n",
    "grt_iv = read_in_file(path_v + 'GCTcoordinates.dat')\n",
    "go_iv = read_in_file(path_v + 'GoCcoordinates.dat')\n",
    "\n",
    "#gr_iv = read_in_file(path_v + fns['gran_coord'])\n",
    "#grt_iv = read_in_file(path_v + fns['gran_t_coord'])\n",
    "#go_iv = read_in_file(path_v + fns['go_coord'])\n",
    "\n",
    "pop_1 =  gr_iv# small dots\n",
    "pop_2 =  go_iv# big dots\n",
    "pop_3 = grt_iv\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "plot3d(ax, pop_1, 'k.', markersize=0.2)\n",
    "plot3d(ax, pop_2, 'r.')\n",
    "plot3d(ax, pop_3, 'b.', markersize=0.2)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "for i, [j, k, tit] in enumerate([[0,1, 'x-y plane'], [1,2, 'y-z plane'], [0,2, 'x-z plane']]):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.plot(pop_1[:,j], pop_1[:,k],  'k.', markersize=0.1)\n",
    "    plt.plot(pop_2[:,j], pop_2[:,k],  'r.')\n",
    "    plt.plot(pop_3[:,j], pop_3[:,k],  'b.', markersize=0.1)\n",
    "\n",
    "print (len(go_iv))\n",
    "print (len(gr_iv))\n",
    "\n",
    "x_go = go_iv[:,0]\n",
    "plt.figure()\n",
    "plt.plot(np.sort(x_go))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-07T14:01:11.710066Z",
     "start_time": "2017-11-07T14:01:11.570975Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! ls brep-ivan/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-07T14:04:09.992546Z",
     "start_time": "2017-11-07T14:04:08.394509Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#n = 9# 3d plot\n",
    "ks= [len(go_gr[i]) for i in range(len(go_gr))]\n",
    "ls= [len(gr_go[i]) for i in range(len(gr_go))]\n",
    "\n",
    "pop_1 =  gr_iv# small dots\n",
    "pop_2 =  go_iv# big dots\n",
    "pts_1 = Go_ori[np.array(list(gr_go[np.argmax(ls)]))]\n",
    "\n",
    "pts_2 = Gr_ori[np.array(list(go_gr[np.argmax(ks)]))]#[np.array(Gid_aa[n]),:]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "plot3d(ax, pop_1, 'k.', markersize=0.2)\n",
    "plot3d(ax, pop_2, 'ro')\n",
    "plot3d(ax, pts_1, 'go')\n",
    "#ax.plot(all_pts[0,0],all_pts[0,1],all_pts[0,2], 'go')\n",
    "plot3d(ax, pts_2, 'bo', markersize=1.0)\n",
    "plt.axis('equal')\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "for i, [j, k, tit] in enumerate([[0,1, 'x-y plane'], [1,2, 'y-z plane'], [0,2, 'x-z plane']]):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.plot(pop_1[:,j], pop_1[:,k],  'k.', markersize=0.2)\n",
    "    plt.plot(pop_2[:,j], pop_2[:,k],  'ro')\n",
    "    plt.plot(pts_1[:,j], pts_1[:,k], 'go')\n",
    "    plt.plot(pts_2[:,j], pts_2[:,k], 'bo', markersize=4.0)\n",
    "    plt.axis('equal')\n",
    "    plt.title(tit)\n",
    "    \n",
    "plt.figure(figsize=(15,5))\n",
    "for i, [j, k, tit] in enumerate([[0,1, 'x-y plane'], [1,2, 'y-z plane'], [0,2, 'x-z plane']]):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.plot(pop_1[:,j], pop_1[:,k],  'k.', markersize=0.3)\n",
    "    plt.plot(pop_2[:,j], pop_2[:,k],  'ro')\n",
    "    plt.plot(pts_1[:,j], pts_1[:,k], 'go')\n",
    "    plt.plot(pts_2[:,j], pts_2[:,k], 'bo', markersize=2.0)\n",
    "    plt.title(tit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-08T14:55:20.814573Z",
     "start_time": "2017-11-08T14:55:20.243253Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#gr and grt relation: grt = gr + [0, 0, 200]\n",
    "#gr_c = read_in_file(path+fns['gran_coord'])\n",
    "#grt_c = read_in_file(path+fns['gran_t_coord'])\n",
    "print (sum (gr_iv-grt_iv) / len (gr_iv))\n",
    "\n",
    "print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Golgi-Golgi interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T16:34:53.180609Z",
     "start_time": "2017-11-10T16:34:53.078581Z"
    },
    "collapsed": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def conrad_hist (dis, tit ='connectivity radius', n_bins = 100):\n",
    "    '''Plots a histogram of the distances between connected cells\n",
    "    Default number of bins is 100'''\n",
    "    plt.figure()\n",
    "    aux = plt.hist(dis, bins = n_bins)\n",
    "    plt.xlabel('radius')\n",
    "    plt.ylabel('number of connections')\n",
    "    plt.title (tit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-08T15:09:47.838054Z",
     "start_time": "2017-11-08T15:09:47.048915Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## golgi-golgi interactions\n",
    "src = read_in_file(path+fns['go_go_source'])\n",
    "tar = read_in_file(path+fns['go_go_target'])\n",
    "dis = read_in_file(path+fns['go_go_dist'])\n",
    "coord = read_in_file(path+fns['go_coord'])\n",
    "\n",
    "res_n = np.zeros(100)\n",
    "for i in range(100):\n",
    "    #res_n[i] = np.linalg.norm(coord[int(tar[i]),:]-coord[int(src[i]),:])\n",
    "    res_n[i] = (sum((coord[int(tar[i]),:]-coord[int(src[i]),:])**2)**0.5)\n",
    "\n",
    "\n",
    "# Checking out the connectivities per GC\n",
    "#n_Go = 200\n",
    "#source files\n",
    "\n",
    "    \n",
    "conrad_hist(dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-07T14:30:34.647008Z",
     "start_time": "2017-11-07T14:30:33.978110Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "src_g = read_in_file(path+fns['go_go_gap_source'])\n",
    "tar_g = read_in_file(path+fns['go_go_gap_target'])\n",
    "dis_g = read_in_file(path+fns['go_go_gap_dist'])\n",
    "conrad_hist(dis_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notable things\n",
    "- BREP does not seem to take into account the densities from the config file. It just uses the number of Golgi/Granule cells that are defined in its default. The parameters NumGC or NumGoC which is defined in the input dict does not exist in the Parameter.hoc file at all.\n",
    "- BREP does not seem to check for or find out if there is a number of GCT points that is not related to the number of GC points. It just simulates GC points with aa independently of the GCT points that are the origin of the PF\n",
    "- The connectivity also does not correspond "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Golgi cells\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation\n",
    "Shitty here, look at the Check-out-Golgi notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T16:34:53.257530Z",
     "start_time": "2017-11-10T16:34:53.182550Z"
    },
    "collapsed": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def gen_dendrites (som, c_r, c_h, c_m, c_std, c_sp, col = 'kx', plot_fig = False):\n",
    "    '''Generates dendrites as described in the paper:\n",
    "    som = coordinates of somata\n",
    "    c_r = maximal radius of cone\n",
    "    c_h = height of cone\n",
    "    c_m = mean angle for each dendrite (number of elements = number of dendrites per cell)\n",
    "    c_std = standard deviation (degree) for the angle of the dendrite\n",
    "    c_sp = spacing between the points\n",
    "    col = color if plot function is enabled\n",
    "    plot_fig = plot the results?\n",
    "    Returns a list of lists containing arrays with the coordinates of the dendrites\n",
    "    '''\n",
    "    c_n = int(np.linalg.norm([c_r, c_h])/c_sp) #number of points per dendrite\n",
    "    c_gr = np.linspace(0,1,c_n)*np.ones((3, c_n)) #linspace grid between 0 and 1 with c_n elements\n",
    "    b_res = []\n",
    "    for i in range(len(som)): #each cell\n",
    "        som_c = som[i,:]\n",
    "        d_res = []\n",
    "        for cc_m in c_m: #each dendrite\n",
    "            ep_ang = (np.random.randn()*c_std + cc_m)*np.pi/180 #angle\n",
    "            pt = ([np.sin(ep_ang)*c_r, np.cos(ep_ang)*c_r, c_h])*c_gr.T #coordinates of the dendrite = endpoint*grid \n",
    "            if plot_fig: ax.plot(pt[:,0], pt[:,1], pt[:,2], col);\n",
    "            d_res.append(pt+som_c) \n",
    "        b_res.append(d_res)\n",
    "    return b_res\n",
    "\n",
    "a_h = 332.0\n",
    "a_r= 100.0\n",
    "b_h = -6.0\n",
    "b_r = 60.0\n",
    "a_m = [30.0, 120.0]\n",
    "b_m = [-20.0, -240.0]\n",
    "b_std = 10\n",
    "a_std = 10\n",
    "a_sp = 6.6\n",
    "b_sp = 14.4\n",
    "\n",
    "#coord = read_in_file(path+fns['go_coord']) #soma points\n",
    "\n",
    "#a_dend = gen_dendrites(coord, a_r, a_h, a_m, a_std, a_sp, 'gx')\n",
    "#b_dend = gen_dendrites(coord, b_r, b_h, b_m, b_std, b_sp, 'kx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-08T14:16:07.867800Z",
     "start_time": "2017-11-08T14:16:07.400318Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize Golgi cells\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "\n",
    "#read in\n",
    "coord = read_in_file(path+fns['go_coord'])\n",
    "apical = read_in_file(path+fns['go_apical_coord'])\n",
    "basal = read_in_file(path+fns['go_basd_coord'])\n",
    "axon = read_in_file(path+fns['go_axon_coord'])\n",
    "new_ap = read_in_file('new_apical.dat', parse_ignore=False)\n",
    "new_bas = read_in_file('new_basal.dat', parse_ignore=False)\n",
    "new_ax = read_in_file('new_axon.dat', parse_ignore=False)\n",
    "\n",
    "\n",
    "apical = apical.reshape([apical.shape[0],int(apical.shape[1]/3),3])\n",
    "basal = basal.reshape([basal.shape[0],int(basal.shape[1]/3),3])\n",
    "axon = axon.reshape([axon.shape[0],int(axon.shape[1]/3),3])\n",
    "print (axon.shape)\n",
    "new_ap = coord_reshape(new_ap)\n",
    "new_bas = coord_reshape(new_bas)\n",
    "print( new_ax.shape)\n",
    "new_ax = coord_reshape(new_ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-08T14:16:13.175105Z",
     "start_time": "2017-11-08T14:16:13.170020Z"
    },
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dendrite spacing\n",
    "ap = apical[1,:]\n",
    "bas = basal[1,:]\n",
    "resa = [np.linalg.norm(ap[j,:]-ap[j+1,:]) for j in range(len(ap)-1)]\n",
    "resb = [np.linalg.norm(bas[j,:]-bas[j+1,:]) for j in range(len(bas)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-08T14:16:15.221408Z",
     "start_time": "2017-11-08T14:16:14.716952Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "ns = np.arange(1) #neurons to be plotted.\n",
    "\n",
    "plot_somata = True\n",
    "plot_apical = 0\n",
    "plot_basal = 0\n",
    "plot_axon = 0\n",
    "plot_new_ap = 0\n",
    "plot_new_bas  = 0\n",
    "plot_new_ax = 1\n",
    "overlay = 0\n",
    "\n",
    "options= [\n",
    "    (apical, plot_apical, 'kx'),\n",
    "    (basal, plot_basal, 'gx'), \n",
    "    (axon, plot_axon, 'r.'), \n",
    "    (new_ap, plot_new_ap, 'cx'),\n",
    "    (new_bas, plot_new_bas, 'mx'),\n",
    "    (new_ax, plot_new_ax, 'y.')]\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "if plot_somata: \n",
    "    if not overlay: ax.plot(coord[ns,0], coord[ns,1], coord[ns,2], 'bo')\n",
    "    else: ax.plot ([0],[0],[0],'bo')\n",
    "\n",
    "#plot dendrites and axon.\n",
    "for pts, yn, col in options:\n",
    "    for i in ns:\n",
    "        if yn:\n",
    "            if overlay: pt = pts[i,:,:]-coord[i,:]\n",
    "            else: pt = pts[i,:,:]\n",
    "            ax.plot(pt[:,0], pt[:,1], pt[:,2], col)\n",
    "\n",
    "#ax.view_init(30,180)\n",
    "proj2D = True\n",
    "if proj2D:\n",
    "    plt.figure()\n",
    "    for pts, yn, col in options:\n",
    "        for i in ns:\n",
    "            if yn:\n",
    "                if overlay: pt = pts[i,:,:]-coord[i,:]\n",
    "                else: pt = pts[i,:,:]\n",
    "                plt.plot(pt[:,0], pt[:,1], col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-31T10:56:34.126245Z",
     "start_time": "2017-10-31T10:56:34.122943Z"
    }
   },
   "source": [
    "### Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-07T15:58:45.556137Z",
     "start_time": "2017-11-07T15:58:23.883889Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "goc = read_in_file(path_ivan+fns['go_coord'])\n",
    "\n",
    "res = np.zeros((40000, 3))\n",
    "for i in range(200):\n",
    "    for j in range(200):\n",
    "        res[i*200+j,:] = goc[i,:]-coord[j,:]\n",
    "#dist = [coord[i,:]-coord[j,:] for i,j in range(200)]\n",
    "dist = read_in_file(path+fns['go_dist'])\n",
    "\n",
    "#print (res[1:100,:] + dist[:99,:])\n",
    "#the distances file just contains all possible differences betwween the different Golgi cells, rounded in an inconsistant way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Granule cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T16:34:53.362410Z",
     "start_time": "2017-11-10T16:34:53.259632Z"
    },
    "collapsed": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "aa_length = 200.0\n",
    "aa_step = 50.0 #this might have to be adapted if the length is not divisable by step\n",
    "pf_length = 1000.0\n",
    "pf_step = 7.5\n",
    "\n",
    "\n",
    "def gen_aa_and_pf (coo, aa_length, aa_step, pf_length, pf_step, plot = False):\n",
    "    '''3D representation of the ascending axon and parallel fiber \n",
    "    coo (#cellx3 int array) = soma coordinates\n",
    "    aa_length (float) = length of ascending axon\n",
    "    aa_step  (float) = spacing between aa points \n",
    "    pf_length (float) = length of parallel fiber\n",
    "    pf_step (float) = spacing between parallel fiber points\n",
    "    if aa_length%aa_step or pf_length%pf_step is not 0, the step parameter be slightly altered for equal spacing\n",
    "    '''\n",
    "    \n",
    "    if plot:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.gca(projection='3d')\n",
    "    \n",
    "    aa_nd = int(aa_length/aa_step) + 1 \n",
    "    aa_sp = np.linspace(0, aa_length, aa_nd)\n",
    "\n",
    "    pf_nd = int(2*pf_length/pf_step) + 1\n",
    "    pf_sp = np.linspace(-pf_length, pf_length, pf_nd)\n",
    "\n",
    "    aa_dots = np.zeros((len(coo), aa_nd, 3))\n",
    "    pf_dots = np.zeros((len(coo), pf_nd, 3))\n",
    "    for i, som in enumerate(coo):\n",
    "        aa_dots[i] = np.ones((aa_nd, 3))*som\n",
    "        aa_dots[i,:,2] = aa_dots[i,:,2] + aa_sp\n",
    "        pf_dots[i] = np.ones((pf_nd,3))*aa_dots[i,-1, :]\n",
    "        pf_dots[i,:,0] = pf_dots[i,:,0] + pf_sp\n",
    "        if plot:\n",
    "            plot3d(ax, aa_dots[i], 'ko', markersize=1.0)\n",
    "            plot3d(ax, pf_dots[i], 'r.', markersize=1.0)\n",
    "    return aa_dots, pf_dots\n",
    "#an idea: can we not use a wider, but more random spacing? Like that there are less points, but the connectio\n",
    "\n",
    "\n",
    "def gen_aa_random (coo, mol_range  = [230, 430]):\n",
    "    '''Generate aa endpoints with a random aa length (end point will be somewhere in mol_range)'''\n",
    "    aa_dots = np.array([np.array([coo[i], coo[i]]) for i in range(len(coo))])\n",
    "    aa_dots[:,1,2] = np.random.uniform(mol_range[0], mol_range[1], len(aa_dots[:,1,2]))\n",
    "    return aa_dots\n",
    "\n",
    "def gen_aa_fixed (coo, aa_length =230):\n",
    "    '''Generate aa endpoints with fixed aa length'''\n",
    "    aa_dots = np.array([np.array([coo[i], coo[i]]) for i in range(len(coo))])\n",
    "    aa_dots[:,1,2] = aa_dots[:,1,2] + aa_length\n",
    "    return aa_dots\n",
    "\n",
    "# to do: make an arbitrary aa possible\n",
    "def gen_pf_from_aa (aa_dots, pf_length):\n",
    "    '''Generate parallel fiber points from aa points '''\n",
    "    pf_dots = aa_dots.copy()\n",
    "    pf_dots[:,0,2] = pf_dots[:,1,2] #z axis shall be the same\n",
    "    pf_dots[:,0,0] = pf_dots[:,0,0] - pf_length\n",
    "    pf_dots[:,1,0] = pf_dots[:,1,0] + pf_length\n",
    "    \n",
    "    return pf_dots\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T11:22:17.195380Z",
     "start_time": "2017-11-03T11:22:15.339085Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 3D Test\n",
    "coo = Gr_co #[:10,:]\n",
    "aa_d, pf_d = gen_aa_and_pf (coo, aa_length, aa_step, pf_length, pf_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-08T14:57:57.237564Z",
     "start_time": "2017-11-08T14:57:56.950021Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#2D Test\n",
    "aa_d2 = gen_aa_random (coo, mol_range  = [230, 430])\n",
    "aa_d3 = gen_aa_fixed (coo, aa_length =230)\n",
    "\n",
    "pf_d2 = gen_pf_from_aa (aa_d2, pf_length)\n",
    "\n",
    "#aa_d2, pf_d2 = gen_pts_for_2dt (coo, aa_length, pf_length)\n",
    "print (pf_d2.shape)\n",
    "print (aa_d2.shape)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "for i, [j, k, tit] in enumerate([[0,1, 'x-y plane'], [1,2, 'y-z plane'], [0,2, 'x-z plane']]):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.plot(aa_d2 [:,0,j], aa_d2[:,0,k],  'k.', markersize=0.2)\n",
    "    plt.plot(aa_d2 [:,1,j], aa_d2[:,1,k],  'g.', markersize=0.2)\n",
    "    plt.plot(pf_d2 [:,1,j], pf_d2[:,1,k],  'r.', markersize=0.2)\n",
    "    plt.plot(pf_d2 [:,0,j], pf_d2[:,0,k],  'm.', markersize=0.2)\n",
    "    plt.axis('equal')\n",
    "    plt.title(tit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Somata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T16:34:53.512485Z",
     "start_time": "2017-11-10T16:34:53.364260Z"
    },
    "collapsed": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Somata generating method \n",
    "\n",
    "#Dimensions of the Granule cell layer\n",
    "Gc_x = 750\n",
    "Gc_y = 375\n",
    "Gc_z = 200\n",
    "\n",
    "n_Go = int(2000*Gc_x*Gc_y/700/1500)\n",
    "n_Gr = 2000*n_Go\n",
    "#print (n_Go)\n",
    "#print (n_Gr)\n",
    "\n",
    "def gen_random_cell_loc (n_cell, Gc_x, Gc_y, Gc_z):\n",
    "    '''Random generation for cell somatas\n",
    "    n_cell (int) = number of cells\n",
    "    Gc_x, Gc_y, Gc_z (float) = dimensions of volume in which cells shall be distributed\n",
    "    Algorithm will first make a grid that definitely has more elements than n_cell\n",
    "    Each grid field is populated by a cell, then those cells are displaced randomly\n",
    "    Last step is to prune the volume, i.e. remove the most outlying cells until the goal number of cells is left\n",
    "    Returns: cell coordinates'''\n",
    "    # get spacing for grid:\n",
    "    vol_c = Gc_x*Gc_y*Gc_z/n_cell\n",
    "    sp_def = vol_c**(1/3)/2\n",
    "    \n",
    "    #Get grid with a few too many elements\n",
    "    gr = np.asarray([[i,j,k] \n",
    "                     for i in np.arange(0, Gc_x, 2*sp_def)   \n",
    "                     for j in np.arange(0, Gc_y, 2*sp_def) \n",
    "                     for k in np.arange(0, Gc_z, 2*sp_def)])\n",
    "    #random displacement\n",
    "    grc = gr + np.random.randn(*gr.shape)*sp_def\n",
    "    \n",
    "    #then remove the ones that lie most outside to get the correct number of cells:\n",
    "    #First find the strongest outliers\n",
    "    lower = grc.T.ravel()\n",
    "    upper = -(grc-[Gc_x, Gc_y, Gc_z]).T.ravel()\n",
    "    most_out_idx = np.mod(np.argsort(np.concatenate((lower,upper))), len(grc))\n",
    "    #In order to find the right number, must iterate a bit as IDs may occur twice (edges)\n",
    "    del_el = len(grc) - n_cell # number of elements to be deleted\n",
    "    n_del = del_el\n",
    "    while len(np.unique(most_out_idx[:n_del])) < del_el:\n",
    "        n_del = n_del + del_el - len(np.unique(most_out_idx[:n_del]))\n",
    "    #Deletion step\n",
    "    grc = grc[np.setdiff1d(np.arange(len(grc)), most_out_idx[:n_del]),:]\n",
    "    return grc\n",
    "\n",
    "\n",
    "def plot3d (ax, dat, *args, **kwargs):\n",
    "    ax.plot(dat[:,0], dat[:,1], dat[:,2], *args, **kwargs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All population points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-08T14:57:46.927196Z",
     "start_time": "2017-11-08T14:57:33.131321Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the two populations\n",
    "Gr_co = gen_random_cell_loc(n_Gr, Gc_x, Gc_y, Gc_z)\n",
    "Go_co = gen_random_cell_loc(n_Go, Gc_x, Gc_y, Gc_z)\n",
    "\n",
    "# 3d plot\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "plot3d(ax, Gr_co, 'k.', markersize=0.2)\n",
    "plot3d(ax, Go_co, 'ro')\n",
    "\n",
    "#projections\n",
    "plt.figure(figsize=(15,5))\n",
    "for i, [j, k, tit] in enumerate([[0,1, 'x-y plane'], [1,2, 'y-z plane'], [0,2, 'x-z plane']]):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.plot(Gr_co[:,j], Gr_co[:,k],  'k.', markersize=0.2)\n",
    "    plt.plot(Go_co[:,j], Go_co[:,k],  'ro')\n",
    "    plt.axis('equal')\n",
    "    plt.title(tit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assembling the points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T16:34:58.143853Z",
     "start_time": "2017-11-10T16:34:53.514282Z"
    },
    "collapsed": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree as kdt\n",
    "\n",
    "#General slice information\n",
    "Gc_x = 150\n",
    "Gc_y = 30\n",
    "Gc_z = 200\n",
    "#Golgi cell dendrite parameters\n",
    "a_h = 332.0\n",
    "a_r= 100.0\n",
    "b_h = -6.0\n",
    "b_r = 60.0\n",
    "a_m = [30.0, 120.0]\n",
    "b_m = [-20.0, -240.0]\n",
    "b_std = 10\n",
    "a_std = 10\n",
    "a_sp = 6.6\n",
    "b_sp = 14.4\n",
    "#Granule cell parameters\n",
    "aa_length = 200.0\n",
    "aa_step = 50.0 #this might have to be adapted if the length is not divisable by step\n",
    "pf_length = 1000.0\n",
    "pf_step = 7.5\n",
    "\n",
    "#number of cells (use densities later!)\n",
    "Go_dens  = 9.5e-6 # from the paper: n_cells/ym³\n",
    "Gr_Go_ratio = 400\n",
    "\n",
    "\n",
    "def dend_to_default_format (dend):\n",
    "    '''change format of the lists from the gen_dendrites function to cells*points*coordinates'''\n",
    "    dd = np.asarray([np.concatenate((dend[i][0], dend[i][1])) for i in range(len(dend))])\n",
    "    return dd\n",
    "\n",
    "# !! Relies on global variables\n",
    "def full_pop (Gc_x, Gc_y, Gc_z=200, dim2 = True, random_aa = False):\n",
    "    ''' will give you a full population including points for a given size, in order to make generation easier\n",
    "    '''\n",
    "    n_Go = int (Go_dens*Gc_x*Gc_y*Gc_z)\n",
    "    n_Gr = Gr_Go_ratio*n_Go\n",
    "    print ('Number of Golgi cells:',n_Go)\n",
    "    print ('Number of Granule cells:', n_Gr)\n",
    "    # get the two populations4\n",
    "    Gr_co = gen_random_cell_loc(n_Gr, Gc_x, Gc_y, Gc_z)\n",
    "    Go_co = gen_random_cell_loc(n_Go, Gc_x, Gc_y, Gc_z)\n",
    "    # get the dendrites\n",
    "    a_dend = dend_to_default_format(gen_dendrites(Go_co, a_r, a_h, a_m, a_std, a_sp, 'gx'))\n",
    "    b_dend = dend_to_default_format(gen_dendrites(Go_co, b_r, b_h, b_m, b_std, b_sp, 'kx'))\n",
    "    \n",
    "    if dim2:\n",
    "        if random_aa: aa_d = gen_aa_random (Gr_co, mol_range  = [230, 430])\n",
    "        else: aa_d = gen_aa_fixed (Gr_co, aa_length =200)\n",
    "        pf_d = gen_pf_from_aa (aa_d, pf_length)\n",
    "    else: aa_d, pf_d = gen_aa_and_pf(Gr_co, aa_length, aa_step, pf_length, pf_step)\n",
    "        \n",
    "    return (Gr_co, Go_co, a_dend, b_dend,  aa_d, pf_d)\n",
    "    \n",
    "def flatten_cells (dat):\n",
    "    return dat.reshape(dat.shape[0]*dat.shape[1],dat.shape[2])\n",
    "\n",
    "def get_golgi_ind (a_dend, b_dend):\n",
    "    a_ind = (np.ones((a_dend.shape[1], a_dend.shape[0]))*np.arange(a_dend.shape[0])).T\n",
    "    b_ind = (np.ones((b_dend.shape[1], b_dend.shape[0]))*np.arange(b_dend.shape[0])).T\n",
    "    gol_ind = np.concatenate((flatten_cells(np.expand_dims(a_ind, axis = 2)), flatten_cells(np.expand_dims(b_ind, axis = 2)))).astype('int')\n",
    "    return gol_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T16:13:08.233157Z",
     "start_time": "2017-11-10T16:13:08.104488Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " def gen_dendrite (som, c_r, c_h, c_m, c_std, c_sp):\n",
    "        '''Generates dendrites as described in the paper:\n",
    "        c_r = maximal radius of cone\n",
    "        c_h = height of cone\n",
    "        c_m = mean angle for each dendrite (number of elements = number of dendrites per cell)\n",
    "        c_std = standard deviation (degree) for the angle of the dendrite\n",
    "        c_sp = spacing between the points\n",
    "        Returns a list of lists containing arrays with the coordinates of the dendrites\n",
    "        '''\n",
    "        c_n = int(np.linalg.norm([c_r, c_h])/c_sp) #number of points per dendrite\n",
    "        c_gr = np.linspace(0,1,c_n)*np.ones((3, c_n)) #linspace grid between 0 and 1 with c_n elements\n",
    "        b_res = []\n",
    "        idx = []\n",
    "        segs = []\n",
    "        for i in range(len(som)): #each cell\n",
    "            som_c = som[i,:]\n",
    "            d_res = []\n",
    "            d_segs = []\n",
    "            for cc_m in c_m: #each dendrite\n",
    "                ep_ang = (np.random.randn()*c_std + cc_m)*np.pi/180 #angle\n",
    "                pt = ([np.sin(ep_ang)*c_r, np.cos(ep_ang)*c_r, c_h])*c_gr.T #coordinates of the dendrite = endpoint*grid \n",
    "                d_res.append(pt+som_c)\n",
    "                d_segs = d_segs + list(np.arange(c_n))\n",
    "            b_res.append(d_res)\n",
    "            segs.append(d_segs)\n",
    "            idx.append(np.ones(sum([len(d_res[k]) for k in range (len(d_res))]))*i)\n",
    "        return b_res, np.array(idx), np.array(segs)\n",
    "    \n",
    "ap, idx, segs = gen_dendrite(Go_co, a_r, a_h, a_m, a_std, a_sp)\n",
    "\n",
    "print (idx.shape)\n",
    "print (segs.shape)\n",
    "#print (ap.shape)\n",
    "\n",
    "print (a_ind)\n",
    "print (idx)\n",
    "print (a_ind == idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T14:53:40.975451Z",
     "start_time": "2017-11-10T14:53:40.559655Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (a_dend.shape)\n",
    "plt.plot(a_dend[0])\n",
    "\n",
    "a_ind = (np.ones((a_dend.shape[1], a_dend.shape[0]))*np.arange(a_dend.shape[0])).T\n",
    "b_ind = (np.ones((b_dend.shape[1], b_dend.shape[0]))*np.arange(b_dend.shape[0])).T\n",
    "print (a_ind)\n",
    "print (b_ind)\n",
    "\n",
    "gol_ind = np.concatenate((flatten_cells(np.expand_dims(a_ind, axis = 2)), flatten_cells(np.expand_dims(b_ind, axis = 2)))).astype('int')\n",
    "#return gol_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T14:52:05.527818Z",
     "start_time": "2017-11-10T14:52:05.182654Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_Go = int (Go_dens*Gc_x*Gc_y*Gc_z)\n",
    "n_Gr = Gr_Go_ratio*n_Go\n",
    "print (n_Go)\n",
    "print (n_Gr)\n",
    "\n",
    "# get the two populations4\n",
    "Gr_co = gen_random_cell_loc(n_Gr, Gc_x, Gc_y, Gc_z)\n",
    "Go_co = gen_random_cell_loc(n_Go, Gc_x, Gc_y, Gc_z)\n",
    "\n",
    "# get the dendrites\n",
    "a_dend = dend_to_default_format(gen_dendrites(Go_co, a_r, a_h, a_m, a_std, a_sp, 'gx'))\n",
    "b_dend = dend_to_default_format(gen_dendrites(Go_co, b_r, b_h, b_m, b_std, b_sp, 'kx'))\n",
    "\n",
    "# get aa and pf\n",
    "aa_d, pf_d = gen_aa_and_pf(Gr_co, aa_length, aa_step, pf_length, pf_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKL implementation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T10:21:56.675119Z",
     "start_time": "2017-11-03T10:21:56.648191Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Gr_co, Go_co, a_dend, b_dend,  aa_d, pf_d = full_pop (15, 10, Gc_z=200)\n",
    "kt_aa = kdt(flatten_cells(aa_d))\n",
    "kt_pf = kdt(flatten_cells(pf_d))\n",
    "# 4 Golgi cells -> around 40-50 s\n",
    "# 8 Golgis -> around 130 s -> about 4.3e6 pts --> if we represent all aa with 5 pts, this is feasible (will be around 4e6 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-02T14:17:41.129792Z",
     "start_time": "2017-11-02T14:17:27.429379Z"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# connection radius\n",
    "c_rad_aa = 30.0\n",
    "c_rad_pf = 5.0\n",
    "#number of points per granule cell \n",
    "n_pt_aa = aa_d.shape[1]\n",
    "n_pt_pf = pf_d.shape[1]\n",
    "\n",
    "res_aa_a = []\n",
    "for i, pt in enumerate(flatten_cells(a_dend)):\n",
    "    warnings.simplefilter('ignore')\n",
    "    ind, = kt_aa.query_radius(pt, r= c_rad_aa)\n",
    "    res_aa_a.append(np.unique((np.floor(ind/n_pt_aa)).astype('int')))\n",
    "    \n",
    "res_aa_b = []\n",
    "for i, pt in enumerate(flatten_cells(b_dend)):\n",
    "    warnings.simplefilter('ignore')\n",
    "    ind, = kt_aa.query_radius(pt, r= c_rad_aa)\n",
    "    res_aa_b.append(np.unique((np.floor(ind/n_pt_aa)).astype('int')))\n",
    "    \n",
    "\n",
    "    \n",
    "res_pf_a = []\n",
    "gr_f = []\n",
    "for i, pt in enumerate(flatten_cells(a_dend)):\n",
    "    warnings.simplefilter('ignore')\n",
    "    ind, = kt_pf.query_radius(pt, r= c_rad_pf)\n",
    "    if len(ind) > 0: gr_f.append(i)\n",
    "    res_pf_a.append(np.unique((np.floor(ind/n_pt_pf)).astype('int')))\n",
    "    \n",
    "res_pf_b = []\n",
    "for i, pt in enumerate(flatten_cells(b_dend)):\n",
    "    warnings.simplefilter('ignore')\n",
    "    ind, = kt_pf.query_radius(pt, r= c_rad_pf)\n",
    "    if len(ind) > 0: print (i)\n",
    "    res_pf_b.append(np.unique((np.floor(ind/n_pt_pf)).astype('int')))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-02T11:05:03.572127Z",
     "start_time": "2017-11-02T11:05:03.567118Z"
    },
    "collapsed": false
   },
   "source": [
    "### 2D SKL implementation\n",
    "\n",
    "**Idea behind this:**\n",
    "It seems somehow contraintuitive to represent a long line by loads of three-dimensional points.\n",
    "Instead, it could be much more efficient to represent the line as a dot (if necessary, adjust coordinate system) and do a 2-dimensional nn search. Cut off the Golgi cells that lie outside (In that case, the tree consists of the Golgi dendrites)\n",
    "This could come in especially handy for the PF. \n",
    "The AA are represented by far less points, so in order to make it possible that they might not just be straight lines along the z axis, the tree could be constructed from them (4-5 pts), and then for the Golgi dendrites the search is performed.\n",
    "\n",
    "**Possible Caveats:**\n",
    "- The ends are not round\n",
    "- Small random displacements are not possible\n",
    "- For a strongly elongated architecture, it is more complicated, as the number of Golgi cells that are considered uselessly increases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-09T09:11:34.909439Z",
     "start_time": "2017-11-09T09:11:34.204139Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get population\n",
    "Gr_co, Go_co, a_dend, b_dend,  aa_d, pf_d = full_pop (1500*0.1, 700*0.1**0.1, Gc_z=200, dim2 = True)\n",
    "#get the right dendrites\n",
    "\n",
    "# To think about: for the pf only do the search if the points are in the molecular layer.\n",
    "\n",
    "dends = np.concatenate((flatten_cells(a_dend), flatten_cells(b_dend)))\n",
    "dends_yz = dends[:,1:]\n",
    "dends_xy = dends[:,:2]\n",
    "print ('Size of dendritic tree:', len(dends_xy))\n",
    "\n",
    "de_tr_yz = kdt(dends_yz)\n",
    "de_tr_xy = kdt(dends_xy)\n",
    "\n",
    "\n",
    "c_rad_pf = 5\n",
    "c_rad_aa = 30\n",
    "\n",
    "# Golgi indices, apical first\n",
    "a_ind = (np.ones((a_dend.shape[1], a_dend.shape[0]))*np.arange(a_dend.shape[0])).T\n",
    "b_ind = (np.ones((b_dend.shape[1], b_dend.shape[0]))*np.arange(b_dend.shape[0])).T\n",
    "gol_ind = np.concatenate((flatten_cells(np.expand_dims(a_ind, axis = 2)), flatten_cells(np.expand_dims(b_ind, axis = 2)))).astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-09T09:11:41.718742Z",
     "start_time": "2017-11-09T09:11:41.710219Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Sme playing around on the tree\n",
    "aa = de_tr_xy.get_arrays()\n",
    "print (type(aa))\n",
    "print (len(aa))\n",
    "print (len(aa[1]))\n",
    "print (type(aa[1]))\n",
    "ff = de_tr_xy.node_data\n",
    "print (ff)\n",
    "print (len(ff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-09T09:11:57.634164Z",
     "start_time": "2017-11-09T09:11:43.944261Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res_id_pf = []\n",
    "Gid_pf = dict()\n",
    "\n",
    "for i in range(len(Go_co)):\n",
    "    Gid_pf[i] = []\n",
    "\n",
    "min_z = 200-c_rad_pf # minimal z coordinate to make inquiry reasonable (no parallel fibers possible underneath)\n",
    "    \n",
    "print (len(pf_d))\n",
    "for i, pts in enumerate(pf_d):\n",
    "    warnings.simplefilter('ignore')\n",
    "    ind, = de_tr_yz.query_radius(pts[1,1:], r= c_rad_pf)\n",
    "    ind = ind[np.logical_and(dends[ind,0]<pts[1,0], dends[ind,0]>pts[0,0])]\n",
    "    gi = (np.unique(gol_ind[ind])).astype('int')\n",
    "    for k in gi:\n",
    "        Gid_pf[k].append(i)\n",
    "    res_id_pf.append(gi)\n",
    "print (i)\n",
    "    \n",
    "\n",
    "#took 10 minutes for whole size (simplest version, no filtering of height and stuff)\n",
    "    #res_aa_a.append(np.unique((np.floor(ind/n_pt_aa)).astype('int')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-09T09:12:22.231170Z",
     "start_time": "2017-11-09T09:12:05.874100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res_id_aa = []\n",
    "Gid_aa = dict()\n",
    "\n",
    "for i in range(len(Go_co)):\n",
    "    Gid_aa[i] = []\n",
    "\n",
    "min_z = 200-c_rad_aa # minimal z coordinate to make inquiry reasonable (no parallel fibers possible underneath)\n",
    "    \n",
    "for i, pts in enumerate(aa_d):\n",
    "    #if i > 10: break\n",
    "    warnings.simplefilter('ignore')\n",
    "    ind, = de_tr_xy.query_radius(pts[1,:2], r= c_rad_aa)\n",
    "    ind = ind[np.logical_and(dends[ind,2]<pts[1,2], dends[ind,2]>pts[0,2])]\n",
    "    gi = (np.unique(gol_ind[ind])).astype('int')\n",
    "    for k in gi:\n",
    "        Gid_aa[k].append(i)\n",
    "    res_id_aa.append(gi)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-09T09:24:19.469714Z",
     "start_time": "2017-11-09T09:24:15.233284Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open ('aa_to_goc_source.dat', 'w') as s_out, open ('aa_to_goc_target.dat', 'w') as t_out:\n",
    "    for n, rr in enumerate(res_id_aa):\n",
    "        for elem in rr:\n",
    "            s_out.write(str(n)+\"\\n\")\n",
    "            t_out.write(str(elem) + \"\\n\")\n",
    "s_out.close()\n",
    "t_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stats: 28 Golgi cells (150x100)**\n",
    "- Runtime with just appending Golgi indices to result array: 10.3\n",
    "- When adding indices to Golgi array: 10.9 -> efficient!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D SKL, the other way around\n",
    "Idea: Once the tree is constructed, it is fast to search it.\n",
    "It seems to be better to put the large point cloud in the tree and then query for the points of the small cloud.\n",
    "With a Granule-Golgi cell ratio of 400:1, putting the granule cells in the tree might be the better option. For the parallel fiber, the amount of points queried for the dendrites can be further decreased by not searching for the ones that are only in the granule cell layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T15:02:16.018884Z",
     "start_time": "2017-11-06T15:02:15.817656Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pf_tr = kdt(pf_d[:,0,1:])\n",
    "aa_tr = kdt(aa_d[:,0,:2])\n",
    "# The goal is to search for the points of the upper part of dend_a in the pf_tr tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T15:25:13.847167Z",
     "start_time": "2017-11-06T15:25:13.634693Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "go_gr_pf = [set() for i in range(len(Go_co))]\n",
    "gr_go_pf = [set() for i in range(len(Gr_co))]\n",
    "\n",
    "min_z = 230-c_rad_pf # minimal z coordinate to make inquiry reasonable (no parallel fibers possible underneath)\n",
    "    \n",
    "for i, pt in enumerate(dends):\n",
    "    if pt[0] > min_z:\n",
    "        warnings.simplefilter('ignore')\n",
    "        ind, = pf_tr.query_radius(pt[1:], r= c_rad_pf)\n",
    "        ind = ind[np.logical_and(pf_d[ind,0,0]<pt[0], pf_d[ind,1,0]>pt[0])]\n",
    "        go_gr_pf[int(gol_ind[int(i)])].update(ind.astype('int'))\n",
    "        for k in ind:\n",
    "            gr_go_pf[k].add(gol_ind[i])\n",
    "\n",
    "            \n",
    "print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T15:02:26.797733Z",
     "start_time": "2017-11-06T06:02:18.663Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gr_go_aa = [set() for i in range(len(Gr_co))]\n",
    "go_gr_aa = [set() for i in range(len(Go_co))]\n",
    "\n",
    "for i, pt in enumerate(dends):\n",
    "    warnings.simplefilter('ignore')\n",
    "    ind, = aa_tr.query_radius(pt[:2], r= c_rad_aa)\n",
    "    ind = ind[np.logical_and(aa_d[ind,0,2]<pt[2], aa_d[ind,1,2]>pt[2])]\n",
    "    go_gr_aa[gol_ind[i]].update(ind)\n",
    "    for k in ind:\n",
    "        gr_go_aa[k].add(i)\n",
    "\n",
    "print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T19:49:22.671390Z",
     "start_time": "2017-11-03T19:49:22.661271Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tplt = [(), ()]\n",
    "type(tplt)\n",
    "type (tplt[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T12:13:42.191802Z",
     "start_time": "2017-11-03T12:13:40.561918Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 4\n",
    "# 3d plot\n",
    "pts_1 = Go_co[n:n+2]\n",
    "pts_2 = Gr_co[np.array(Gid_aa[n]),:]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "plot3d(ax, Gr_co, 'k.', markersize=0.2)\n",
    "plot3d(ax, Go_co, 'ro')\n",
    "plot3d(ax, pts_1, 'go')\n",
    "#ax.plot(all_pts[0,0],all_pts[0,1],all_pts[0,2], 'go')\n",
    "plot3d(ax, pts_2, 'b.', markersize=0.4)\n",
    "plt.axis('equal')\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "for i, [j, k, tit] in enumerate([[0,1, 'x-y plane'], [1,2, 'y-z plane'], [0,2, 'x-z plane']]):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.plot(Gr_co[:,j], Gr_co[:,k],  'k.', markersize=0.2)\n",
    "    plt.plot(Go_co[:,j], Go_co[:,k],  'ro')\n",
    "    plt.plot(pts_1[:,j], pts_1[:,k], 'go')\n",
    "    plt.plot(pts_2[:,j], pts_2[:,k], 'b.', markersize=4.0)\n",
    "    plt.axis('equal')\n",
    "    plt.title(tit)\n",
    "    \n",
    "plt.figure(figsize=(15,5))\n",
    "for i, [j, k, tit] in enumerate([[0,1, 'x-y plane'], [1,2, 'y-z plane'], [0,2, 'x-z plane']]):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.plot(Gr_co[:,j], Gr_co[:,k],  'k.', markersize=0.3)\n",
    "    plt.plot(Go_co[:,j], Go_co[:,k],  'ro')\n",
    "    plt.plot(pts_1[:,j], pts_1[:,k], 'go')\n",
    "    plt.plot(pts_2[:,j], pts_2[:,k], 'b.', markersize=2.0)\n",
    "    plt.title(tit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scipy implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-02T10:39:28.212361Z",
     "start_time": "2017-11-02T10:39:27.611098Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import KDTree as kdt2\n",
    "\n",
    "aa_d2 = aa_d.reshape(aa_d.shape[0]*aa_d.shape[1], aa_d.shape[2])\n",
    "\n",
    "def flatten_cells (dat):\n",
    "    return dat.reshape(dat.shape[0]*dat.shape[1],dat.shape[2])\n",
    "\n",
    "\n",
    "kt2 = kdt2(aa_d2)\n",
    "# connection radius\n",
    "c_rad = 30.0\n",
    "n_pt_aa = 5\n",
    "\n",
    "res = []\n",
    "for i, pt in enumerate(flatten_cells(b_dend)):\n",
    "    ind = kt2.query_ball_point(pt, r= c_rad)\n",
    "    ind = np.asarray(ind)\n",
    "    #print (len(ind[0]))\n",
    "    #print (len(np.floor(ind[0]/n_pt_aa)))\n",
    "    res.append((np.floor(ind/n_pt_aa)).astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-01T14:26:44.652002Z",
     "start_time": "2017-11-01T14:26:44.591409Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### deprecated!\n",
    "\n",
    "all_pts = np.zeros((1,3))\n",
    "pt_order = [a_dend, b_dend, aa_d]\n",
    "start_ind = np.zeros(len(pt_order))\n",
    "pts_per_cell = np.zeros(len(pt_order))\n",
    "\n",
    "for i, pts in enumerate(pt_order):    \n",
    "    pts_f = pts.reshape(pts.shape[0]*pts.shape[1], pts.shape[2])\n",
    "    print (pts_f.shape)\n",
    "    start_ind[i] = len(all_pts)-1\n",
    "    pts_per_cell[i] = pts.shape[1]\n",
    "    all_pts = np.concatenate((all_pts, pts_f))\n",
    "all_pts = all_pts[1:,:]\n",
    "\n",
    "print (start_ind)\n",
    "print (pts_per_cell)\n",
    "\n",
    "aa_d2 = aa_d.reshape(aa_d.shape[0]*aa_d.shape[1], aa_d.shape[2])\n",
    "\n",
    "kt = kdt(aa_d2)\n",
    "# connection radius\n",
    "c_rad = 30.0\n",
    "# The index at which the source ids start\n",
    "so_ind_start = int (start_ind[2])\n",
    "# source cells: number of points per cell\n",
    "so_ppc = pts_per_cell [2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Golgi-Golgi Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T16:34:58.269859Z",
     "start_time": "2017-11-10T16:34:58.145583Z"
    },
    "collapsed": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "#Calculate Golgi-to-Golgi distances\n",
    "def get_distances (goc):\n",
    "    '''brute force distance calculation between all cells in a population goc'''\n",
    "    dis = np.zeros((len(goc), len(goc)))\n",
    "    for i in range(len(goc)):\n",
    "        for j in range(i):\n",
    "            dd = np.linalg.norm(goc[i,:] - goc[j,:])\n",
    "            dis[i,j] = dd\n",
    "            dis[j,i] = dd #\n",
    "    return dis\n",
    "\n",
    "# Increase or decrease k taking into account previous values         \n",
    "def change_kTi (kTi, kTi_trace, decrease = False):\n",
    "    ''' Increase or decrease 1/kT while taking into account the values so far:\n",
    "    if kTi is currently the biggest/smallest that it has been in his entire history, it is doubled/halfed,\n",
    "    otherwise the mean of the current value and the next biggest/smallest value of the history will be used.\n",
    "    kTi = current 1/kT\n",
    "    kTi_trace = values tried so far\n",
    "    decrease: set True if kTi should be decreased, default is increase\n",
    "    Returns: new kTi'''\n",
    "    ks = np.sort(np.array(kTi_trace))\n",
    "    if decrease: ks = ks[::-1]\n",
    "    if kTi == ks[-1]: \n",
    "        if not decrease: return kTi*2\n",
    "        else: return kTi/2\n",
    "    else: return (ks[np.where(ks == kTi)[0]+1]+kTi)/2\n",
    "    \n",
    "# Print some statistics for the current kTi value \n",
    "def rad_prob_stats(kTi, prs = [0.5, 0.2], rad = [100]):\n",
    "    '''For the current kTi value, will give the connection probability radii for certain connection probabilities.\n",
    "    kTi = current kTi\n",
    "    prs = probabilities of interest'''\n",
    "    print ('At 1/kT = ', float(kTi) ,'Boltzmann distribution leads to the following relations of connection prob and distance:')\n",
    "    for pr in prs:\n",
    "        print ('Conn. prob', pr, 'at distance', float(np.round(-np.log(pr)/kTi, 2)))\n",
    "    for r in rad:\n",
    "        print ('At radius', r, 'conn. prob. is', float(np.round(np.exp(-kTi*r),4)))\n",
    "        \n",
    "\n",
    "def get_Boltzmann_conn (dis, kTi):\n",
    "    '''\n",
    "    Get a connectivity matrix that is determined by connection probabilities depending on th Boltzmann distribution \n",
    "    at 1/kT =  kTi\n",
    "    '''\n",
    "    edis = np.tril(np.exp(-kTi*dis) - np.eye(len(dis))) # exponentiated distance -> probability of connection\n",
    "    conn = edis > np.random.rand(*edis.shape) #random number -> connection?\n",
    "    return conn\n",
    "    \n",
    "def fit_Boltzmann(dis, goal_range):\n",
    "    '''Adapt the kTi value so that the connectivity is in the range that is wanted.'''\n",
    "    n_found = 0 # init value for the average number of connections per cell\n",
    "    kTi = 1 # init value for the inverse of k(Boltzmann constant) and the temperature T\n",
    "    kTi_trace = [kTi]  # init for the storing of kTi values\n",
    "    while (n_found < goal_range[0] or n_found > goal_range[1]) and len(kTi_trace) < 50:   \n",
    "        conn = get_Boltzmann_conn (dis, kTi)\n",
    "        n_found = np.mean(sum(conn))*2 # average number of connection per cell\n",
    "        if n_found > goal_range [1]: kTi = change_kTi(kTi, kTi_trace) # too many connections -> increase the temp\n",
    "        elif n_found < goal_range[0]: kTi = change_kTi(kTi, kTi_trace, True) # not enough connections -> decrease the temp\n",
    "        kTi_trace.append(kTi)\n",
    "    return kTi, conn\n",
    "\n",
    "def conn_matrix_to_list (conn):\n",
    "    #Change from the bool connectivity matrix to lists as known\n",
    "    res = [set() for i in range(len(conn))] \n",
    "    src = []\n",
    "    tar = []\n",
    "    st_dis = []\n",
    "    for i in range(len(goc)):\n",
    "        res[i].update(np.where(conn[i,:])[0])\n",
    "        res[i].update(np.where(conn[:,i])[0])\n",
    "        tar.extend(res[i])\n",
    "        if len(res[i])>0:\n",
    "            src.extend(i*np.ones(len(res[i])))\n",
    "            st_dis.extend(list(dis [i,np.array(list(res[i]))])) # for this one we kept the full symmetric distance matrix\n",
    "    return res, src, tar, st_dis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gap junctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-08T14:02:47.462996Z",
     "start_time": "2017-11-08T14:02:46.067006Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "goc = read_in_file(path_ivan+fns['go_coord'])\n",
    "dis = get_distances(goc)\n",
    "\n",
    "goal_range = [13.0, 14.0] #Goal range of number of average connections per cell    \n",
    "\n",
    "kTi_gj, conn_gj = fit_Boltzmann (dis, goal_range)\n",
    "\n",
    "res_gj, src_gj, tar_gj, dis_gj = conn_matrix_to_list(conn_gj)        \n",
    "\n",
    "rad_prob_stats(kTi_gj)\n",
    "conrad_hist(dis_gj) \n",
    "target_stats(np.array(tar_gj),'Golgi-to-Golgi gap junctions:')\n",
    "\n",
    "#l_res_gj = [len(res_gj[l]) for l in range(len(res_gj))] #check for the number of connections per cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synaptic connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-08T14:02:51.072378Z",
     "start_time": "2017-11-08T14:02:50.610685Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kTi_syn = -np.log(0.2)/50 # connection prob should be 20% at 50 ym, value from paper\n",
    "\n",
    "conn_syn = get_Boltzmann_conn(dis, kTi_syn)\n",
    "res_syn, src_syn, tar_syn, dis_syn = conn_matrix_to_list(conn_syn)\n",
    "\n",
    "conrad_hist (dis_syn)    \n",
    "target_stats(np.array(tar_syn),'Golgi-to-Golgi synaptic connections')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-08T12:54:20.501713Z",
     "start_time": "2017-11-08T12:54:20.498623Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import networkx as nx\n",
    "print (len(st_dis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-08T12:42:50.952232Z",
     "start_time": "2017-11-08T12:42:50.947816Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (np.array(list(res[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example dataset#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the data, generate aa, pf, and dendritic tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-09T10:47:59.902148Z",
     "start_time": "2017-11-09T10:47:54.912742Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read in files\n",
    "gr_ex = read_in_file(path_dropin + 'GCcoordinates.dat')[:80000]\n",
    "go_ex = read_in_file(path_dropin + 'GoCcoordinates.dat')[:200]\n",
    "\n",
    "#generate dendrites for Golgi cells\n",
    "a_dend = dend_to_default_format(gen_dendrites(go_ex, a_r, a_h, a_m, a_std, a_sp))\n",
    "b_dend = dend_to_default_format(gen_dendrites(go_ex, b_r, b_h, b_m, b_std, b_sp))\n",
    "dends = np.concatenate((flatten_cells(a_dend), flatten_cells(b_dend)))\n",
    "#and the corresponding Golgi cell indices\n",
    "gol_ind = get_golgi_ind (a_dend, b_dend)\n",
    "\n",
    "#generate aa and pf\n",
    "aa_d = gen_aa_fixed (gr_ex, aa_length =230)\n",
    "pf_d = gen_pf_from_aa (aa_d, pf_length)\n",
    "\n",
    "#construct the 2d-trees\n",
    "pf_tr = kdt(pf_d[:,0,1:])\n",
    "aa_tr = kdt(aa_d[:,0,:2])\n",
    "\n",
    "#critical radii\n",
    "c_rad_pf = 5\n",
    "c_rad_aa = 30\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel fiber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-09T10:48:08.837453Z",
     "start_time": "2017-11-09T10:48:04.015930Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "go_gr_pf = [set() for i in range(len(go_ex))]\n",
    "gr_go_pf = [set() for i in range(len(gr_ex))]\n",
    "\n",
    "min_z = 230-c_rad_pf # minimal z coordinate to make inquiry reasonable (no parallel fibers possible underneath)\n",
    "    \n",
    "for i, pt in enumerate(dends):\n",
    "    if pt[0] > min_z:\n",
    "        warnings.simplefilter('ignore')\n",
    "        ind, = pf_tr.query_radius(pt[1:], r= c_rad_pf)\n",
    "        ind = ind[np.logical_and(pf_d[ind,0,0]<pt[0], pf_d[ind,1,0]>pt[0])]\n",
    "        go_gr_pf[int(gol_ind[int(i)])].update(ind.astype('int'))\n",
    "        for k in ind:\n",
    "            gr_go_pf[int(k)].add(int(gol_ind[int(i)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ascending axon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-09T10:50:39.611942Z",
     "start_time": "2017-11-09T10:50:30.796334Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gr_go_aa = [set() for i in range(len(gr_ex))]\n",
    "go_gr_aa = [set() for i in range(len(go_ex))]\n",
    "\n",
    "for i, pt in enumerate(dends):\n",
    "    warnings.simplefilter('ignore')\n",
    "    ind, = aa_tr.query_radius(pt[:2], r= c_rad_aa)\n",
    "    ind = ind[np.logical_and(aa_d[ind,0,2]<pt[2], aa_d[ind,1,2]>pt[2])]\n",
    "    go_gr_aa[int(gol_ind[i])].update(ind)\n",
    "    for k in ind:\n",
    "        gr_go_aa[int(k)].add(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization 1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-09T10:50:43.004084Z",
     "start_time": "2017-11-09T10:50:41.330365Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_1 =  gr_ex# small dots\n",
    "pop_2 =  go_ex# big dots\n",
    "pop_3 = aa_d[:,1,:] #blue dots\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "plot3d(ax, pop_1, 'k.', markersize=0.2)\n",
    "plot3d(ax, pop_2, 'r.')\n",
    "plot3d(ax, pop_3, 'b.', markersize=0.2)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "for i, [j, k, tit] in enumerate([[0,1, 'x-y plane'], [1,2, 'y-z plane'], [0,2, 'x-z plane']]):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.plot(pop_1[:,j], pop_1[:,k],  'k.', markersize=0.1)\n",
    "    plt.plot(pop_2[:,j], pop_2[:,k],  'r.')\n",
    "    plt.plot(pop_3[:,j], pop_3[:,k],  'b.', markersize=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-09T10:58:21.311751Z",
     "start_time": "2017-11-09T10:58:20.116169Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "go_gr_pf_l = [len(go_gr_pf[i]) for i in range(len(go_gr_pf))]\n",
    "n = np.argmax(go_gr_pf_l)\n",
    "print (np.argmax(go_gr_pf_l))\n",
    "print (max (go_gr_pf_l))\n",
    "\n",
    "pop_1 =  gr_ex# small dots\n",
    "pop_2 =  go_ex# big dots\n",
    "pop_3 = gr_ex[(np.array(list(go_gr_pf[n]))).astype('int'), :] #blue dots\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "plot3d(ax, pop_1, 'k.', markersize=0.2)\n",
    "plot3d(ax, pop_2, 'r.')\n",
    "plot3d(ax, pop_3, 'b.', markersize=1.0)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "for i, [j, k, tit] in enumerate([[0,1, 'x-y plane'], [1,2, 'y-z plane'], [0,2, 'x-z plane']]):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.plot(pop_1[:,j], pop_1[:,k],  'k.', markersize=0.2)\n",
    "    plt.plot(pop_2[:,j], pop_2[:,k],  'r.')\n",
    "    plt.plot(pop_3[:,j], pop_3[:,k],  'b.', markersize=1.0)\n",
    "    plt.plot(go_ex[n,j], go_ex[n,k], 'go')\n",
    "    plt.title(tit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-31T14:12:48.149480Z",
     "start_time": "2017-10-31T14:12:48.127072Z"
    }
   },
   "source": [
    "## Kd-Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Background\n",
    "\n",
    "- binary search stree\n",
    "    - every branching node contains a k-dimensional point\n",
    "    - every leaf node contains a set of points\n",
    "- every branching node represents a splitting hyperplane that divides the space into two half-spaces    \n",
    "    - left of the splitting hyperplane = left subtree, same for richt\n",
    "    - each spliitting hyperplane is perpendicular to one of the axes in the k-dimensional space\n",
    "    - the axes for the splitting hyperplanes are rotating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On the chicken kd-tree library:\n",
    "- works with datastructure POINT3D\n",
    "    - constructor: make-point3d dbl dbl dbl \n",
    "    - accessors point3d-x /y/z\n",
    "    - predicate: point3d?\n",
    "- KD-Tree itself\n",
    "    - constructor: list->kd-tree (list of POINT3D)\n",
    "    - predicates: kd-tree? -> checks object, kd-tree-empty?, \n",
    "        - kd-tree-is-valid? -> checks if all points in subtree lie on left side of hyperplane and right on right\n",
    "        - kd-tree-all-subtrees-are-valid? -> valid property for all branching nodes?\n",
    "    - accessors: \n",
    "        - kd-tree->list  -> all the points contained in tree in a POINT3D list\n",
    "        - kd-tree->list\\* -> list with elements of the form (i . POINT3D) -> i is the relative integer index of the point\n",
    "     \n",
    "for other accessors, the author was not motivated enough to write a description.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Pythonic Kd-Tree libraries:\n",
    "\n",
    "#### Scipy:\n",
    "- Documentation: https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.spatial.KDTree.html\n",
    "- Source Code: https://github.com/scipy/scipy/blob/master/scipy/spatial/kdtree.py\n",
    "- Algorithm reference Maneewongvatana and Mount 1999\n",
    "- Can be queried for r nearest neighbors, however r should be relatively small because elsewise, brute force is just as efficient.\n",
    "- Approximate nearest neighbors seems to be another, and much faster option, and might work well for us.\n",
    "- Uses pythonic libraries. \n",
    "- The heap queue algorithm: https://github.com/python/cpython/blob/2.7/Lib/heapq.py seems to be used, but it is also in python\n",
    "\n",
    "\n",
    "#### SKlearn:\n",
    "- Documentation: http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html\n",
    "- Source Code: https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/neighbors/kd_tree.pyx\n",
    "- uses cython. Might thus be faster. Let's check.\n",
    "\n",
    "\n",
    "Neither of them appears to have parallelization supported right from the beginning.\n",
    "Both just take regular arrays as inputs.\n",
    "\n",
    "\n",
    "Could be interesting:\n",
    "http://ieeexplore.ieee.org/abstract/document/5654017/?reload=true\n",
    "GPU implementation for kNN search\n",
    "Following this:\n",
    "https://link.springer.com/chapter/10.1007/978-3-642-38628-2_67\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import KDTree as T_sp\n",
    "from sklearn.neighbors import KDTree as T_sk\n",
    "s_dat = np.asarray(import_csv(fn_out))\n",
    "import time\n",
    "\n",
    "rn = np.random.randint(0, len(s_dat), 50)\n",
    "nn = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (s_dat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_dist = np.zeros((len(rn), nn))\n",
    "k_ind = np.zeros((len(rn), nn))\n",
    "tk0 = time.time()\n",
    "kt = T_sk(s_dat)\n",
    "tk1 = time.time()\n",
    "for i, ii in enumerate(rn):\n",
    "    warnings.simplefilter('ignore') #definitely not ideal. But no clue how the validation file gets called\n",
    "    k_dist[i,:], k_ind [i,:] = kt.query(s_dat[ii,:], k = nn)\n",
    "tk2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_dist = np.zeros((len(rn), nn))\n",
    "p_ind = np.zeros((len(rn), nn))\n",
    "tp0 = time.time()\n",
    "pt = T_sp(s_dat)\n",
    "tp1 = time.time()\n",
    "for i, ii in enumerate(rn):\n",
    "    p_dist[i,:], p_ind [i,:] = pt.query(s_dat[ii,:], k = nn)\n",
    "tp2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Here is the first, blunt comparison of both algorithms in terms of time:\n",
    "print (tk1-tk0)\n",
    "print (tp1-tp0)\n",
    "\n",
    "print (tk2-tk1)\n",
    "print (tp2-tp1)\n",
    "#Scikit-learn is way faster.\n",
    "\n",
    "#print (np.isclose (k_dist, p_dist))\n",
    "#print (k_ind -p_ind) \n",
    "# Where the indices are not the same it is because the distances are equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reading in, subsampling and storing again the csv files in order to have a smaller dataset at hand that has a similar density anyway.\n",
    "\n",
    "import csv\n",
    "\n",
    "fn_in = 'input_files/GCTcoordinates.dat'\n",
    "fn_out = 'input_files/GCT_small.dat' #100x150 -> 11 k\n",
    "fn_out2 = 'input_files/GCT_smallsmall.dat' #30x100 -> 2.2k\n",
    "fn_out3 = 'input_files/GCT_tiny.dat' # 2x5 ->  6\n",
    "\n",
    "x_r = [0.0, 2.0]\n",
    "y_r = [0.0, 5.0]\n",
    "z_r = [0.0, 1000.0]\n",
    "rrs = [x_r, y_r, z_r]\n",
    "\n",
    "def subsample_coords (rrs, fn_in, fn_out = 'input_files/downsampled.dat', save = True):\n",
    "    res = []\n",
    "    rnr = [0, 0]\n",
    "    with open(fn_in, newline = '') as f, open (fn_out, 'w', newline = '') as w_f:\n",
    "        rr = csv.reader(f, delimiter = ' ')\n",
    "        if save: wr = csv.writer(w_f, delimiter = ' ')\n",
    "        for line in rr:\n",
    "            in_range = all([float(line[i])>rrs[i][0] and float(line[i])<rrs[i][1] for i in range(len(rrs))]) #check if in range\n",
    "            if in_range: \n",
    "                if save: wr.writerow([float(line[j]) for j in range(len(rrs))])\n",
    "                res.append([float(line[j]) for j in range(len(rrs))])\n",
    "                rnr[0] = rnr[0]+1\n",
    "            else:\n",
    "                rnr[1] = rnr[1]+1\n",
    "    print ('Subsampled {} of {}'.format(rnr[0], rnr[1]))\n",
    "    return res\n",
    "\n",
    "#my_s = subsample_coords (rrs, fn_in, fn_out3, save = True)\n",
    "\n",
    "def import_csv (fn):\n",
    "    res = []\n",
    "    with open (fn, newline = '') as f:\n",
    "        rr = csv.reader(f, delimiter = ' ')\n",
    "        for line in rr:\n",
    "            res.append([float(line[j]) for j in range(len(line))])\n",
    "    return np.asarray(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random and deprecated stuff below this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Development site for the read_in_config function.\n",
    "\n",
    "#from neuron import hoc, h\n",
    "# weird thing that I did not get yet: despite all the copy statements, the second time you calculate d_l, it would give 0. \n",
    "# Thus, the hoc objects must somehow take on each other's parameters... \n",
    "\n",
    "#load an empty hoc object and find out which parameters are native to that object (probably useless...)\n",
    "empty_hoc = dir(neuron.hoc.HocObject()).copy()\n",
    "config_fn = './input_files/Parameters.hoc'\n",
    "overwrite_config =  True\n",
    "#load our own hoc object from the parameter file, get the disjunct list of parameters (probably useless...)\n",
    "neuron.h.xopen(config_fn)\n",
    "full_hoc = dir(neuron.h)\n",
    "if 'd_l' not in globals():\n",
    "    d_l = list (set (full_hoc)  - set (empty_hoc)).copy()\n",
    "\n",
    "#c_d = b.config_dict\n",
    "c_d = dict((v,k) for k,v in b.config_dict.items()) #exchange key and value\n",
    "#this dict translates the parameters used in the Parameters file to the ones used in the code\n",
    "# Check if the Brep object contains the right parameters and if so, change them.\n",
    "# Note: Resolve conflicts with the command line - I think default should be that command line should has priority \n",
    "self = b\n",
    "for h_k in full_hoc:\n",
    "    if h_k in c_d.keys() and h_k not in self.cl_args.keys():\n",
    "        if hasattr (self.args, c_d[h_k]):\n",
    "            setattr (self.args, c_d[h_k], getattr (neuron.h, h_k))\n",
    "        else:\n",
    "            print ('Did not find {}'.format(c_d[h_k]))\n",
    "    elif h_k in c_d.keys() and h_k in self.cl_args.keys():\n",
    "        if hasattr (self.args, c_d[h_k]):\n",
    "            if overwrite_config:\n",
    "                warnings.warn('Parameter {} was set both by command line and in config, will use value from command line'.format(c_d[h_k]))\n",
    "            else:\n",
    "                warnings.warn('Parameter {} was set both by command line and in config, will use value from config file'.format(c_d[h_k]))\n",
    "                setattr (self.args, c_d[h_k], getattr (neuron.h, h_k))\n",
    "    \n",
    "# The following two parameters are an exception:\n",
    "if 'GLdepth' in d_l and 'PCLdepth' in d_l and not 'aa-length' in self.cl_args.keys():\n",
    "    setattr (self.args, 'aa-length', getattr(neuron.h, 'GLdepth')+getattr(neuron.h,'PCLdepth'))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### The transformations of the parameters, automized in a small parser script.\n",
    "\n",
    "#Had to be done only once, but will be kept for reference.\n",
    "\n",
    "from neuron import hoc, h\n",
    "# weird thing that I did not get yet: despite all the copy statements, the second time you calculate d_l, it would give 0. \n",
    "# Thus, the hoc objects must somehow take on each other's parameters... \n",
    "\n",
    "#load an empty hoc object and find out which parameters are native to that object (probably useless...)\n",
    "empty_hoc = dir(hoc.HocObject()).copy()\n",
    "config_fn = './input_files/Parameters.hoc'\n",
    "#load our own hoc object from the parameter file, get the disjunct list of parameters (probably useless...)\n",
    "h.xopen(config_fn)\n",
    "full_hoc = dir(h).copy()\n",
    "if 'd_l' not in globals():\n",
    "    d_l = list (set (full_hoc)  - set (empty_hoc)).copy()\n",
    "\n",
    "# Code file\n",
    "tf = 'brep_commented.scm'\n",
    "# Step one: parse all lines that contain both config or options as those are the ones that \n",
    "res_dict = {}\n",
    "with open (tf, 'rb') as tff:\n",
    "    for line in tff:\n",
    "        st = str(line)\n",
    "        c = st.find (\"config '\")\n",
    "        o = st.find (\"options '\") \n",
    "        if c > 0 and o > 0:\n",
    "            c_clb = st[c:].find (')')\n",
    "            o_clb = st[o:].find (')')\n",
    "            res_dict[st[c+8:c+c_clb]] = st[o+9:o+o_clb] \n",
    "    tff.close()\n",
    "\n",
    "#parameters that are defined in the res file but have not been parsed yet\n",
    "rest_hk = (set (d_l)- set(res_dict.keys()))\n",
    "rem = {}\n",
    "#check if they occur in the code\n",
    "with open ('brep_commented.scm', 'rb') as f_in:\n",
    "    n = 0\n",
    "    for line in f_in:\n",
    "        n = n+1\n",
    "        for w in rest_hk:\n",
    "            if str(line).find(w)>0:\n",
    "                if w in rem.keys():\n",
    "                    rem[w].append(n)\n",
    "                else:\n",
    "                    rem[w] = [n]                  \n",
    "print (rem) # 'TS is coincidental, the other two parameters are taken seperate care of.\n",
    "\n",
    "#print the resulting dict to a file.\n",
    "with open ('par_d2.txt', 'w') as f_out:\n",
    "    for k in res_dict.keys():\n",
    "        f_out.write(\"'\" +res_dict[k]+ \"' : '\"+k+ \"', \\n\" )\n",
    "\n",
    "#print (res_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Used this to try out command line calls. \n",
    "\n",
    "#Brep = importlib.reload(BREPpy)\n",
    "#stupid workaround so that the known command line call can be kept up.\n",
    "#I think I changed something, would have to git checkout....\n",
    "class Brep2 (Brep, b):\n",
    "    def __init__:\n",
    "        self.args = b.args\n",
    "        self.config_dict = b.config_dict\n",
    "        self.cl_args = b.cl_args\n",
    "        \n",
    "\n",
    "\n",
    "def new_Brep (arg_dict = {}, **kwargs):\n",
    "    if True: #delete and make new Brep file\n",
    "        ! python ~/Desktop/LabRot_OIST/pybrep/BREPpy.py --config_file blabla \n",
    "        a = pkl.load(open('./tmp.pkl', 'rb'))\n",
    "        ! rm tmp.pkl\n",
    "        b = Brep2(a)\n",
    "    else: b = Brep2(pkl.load(open('./tmp.pkl', 'rb'))) \n",
    "    #Process and add arguments    \n",
    "    arg_dict.update(kwargs)\n",
    "    for k in arg_dict.keys():\n",
    "        if hasattr (b.args, k):\n",
    "            setattr (b.args, k, arg_dict[k])\n",
    "        else:\n",
    "            warnings.warn ('Keyline argument {} not known'.format(k))\n",
    "            \n",
    "    return b\n",
    "\n",
    "arg_dict = {'config_file': 'blabla.c',\n",
    "            'verbose': True}\n",
    "b = new_Brep(arg_dict, gc_points_fn = 'yipyip' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Fun with magic\n",
    "\n",
    "# http://ipython.readthedocs.io/en/stable/interactive/magics.html\n",
    "#notable ones\n",
    "# %debug #-> debug stuff. Lets you inspect the stack frame of an exception interactively\n",
    "# %env #-> see all env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-31T14:27:47.660245Z",
     "start_time": "2017-10-31T14:27:47.511968Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Used this to develop the soma rendering algorithm\n",
    "\n",
    "dat = Gr_co\n",
    "\n",
    "print (dat.shape)\n",
    "\n",
    "lower = dat.T.ravel()\n",
    "upper = -(dat-[Gc_x, Gc_y, Gc_z]).T.ravel()\n",
    "most_out_idx = np.mod(np.argsort(np.concatenate((lower,upper))), len(dat))\n",
    "\n",
    "n_del = 500\n",
    "dat = dat[np.setdiff1d(np.arange(len(dat)), most_out_idx[:n_del]),:]\n",
    "\n",
    "print (dat.shape)\n",
    "\n",
    "test_ar = np.array([[0,1,3],[-1,3,5],[2,3,4], [5,3,2]])\n",
    "print (test_ar.ravel())\n",
    "print (np.argsort(test_ar.T.ravel()))\n",
    "tt2 = test_ar- [1,2,3]\n",
    "print (tt2)\n",
    "\n",
    "print ('')\n",
    "most_out = np.argsort(np.concatenate(( test_ar.T.ravel(), -(test_ar-[1,2,3]).T.ravel() )))\n",
    "\n",
    "most_out_idx = np.mod(most_out, len(test_ar))\n",
    "\n",
    "print (len(test_ar))\n",
    "print( -(test_ar-[1,2,3]))\n",
    "print( -(test_ar-[1,2,3]).ravel())\n",
    "print (np.argsort( -(test_ar-[1,2,3]).ravel()))\n",
    "\n",
    "print ('')\n",
    "print (np.concatenate(( test_ar.ravel(), -(test_ar-[1,2,3]).ravel() )))\n",
    "print (most_out)\n",
    "print (most_out_idx)\n",
    "print \n",
    "\n",
    "print ('')\n",
    "print (test_ar)\n",
    "print( -(test_ar-[1,2,3]))\n",
    "#hs = np.sum(np.heaviside(-dat) + np.heaviside(dat-[Gc_x, Gx_y, Gc_z]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(332**2 + 100**2)**0.5 / 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(6**2+60**2)**0.5/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "854px",
    "left": "0px",
    "right": "1262.9px",
    "top": "108px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
