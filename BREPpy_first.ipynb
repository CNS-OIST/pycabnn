{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BREPpy sandbox\n",
    "\n",
    "\n",
    "**So far:**\n",
    "- Generate the cell-representing dots\n",
    "- Implement knn-search\n",
    "    - (Optimize speed -> Parallelize!)\n",
    "- Write tests (General correct function, Comparison with scheme-BREP)\n",
    "\n",
    "**Open questions:**\n",
    "- How was the spacing \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the Parameter file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not nice: there are about 4 different names for one variable- there are the default ones in the code, the assigned ones in the code, and the ones in the parameter file. \n",
    "I will use variables that are similar to the ones defined in the grammar in the code, with the difference that they will be adapted to Python syntax ( _ instead of -), and a few have an additional postfix to clarify what they do (e.g. \\_fn = filename) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On the installation of neuron\n",
    "Neuron did not really work out of the box for me. \n",
    "I (ubuntu 16.04 LTS, 64 bit) did it the following way:\n",
    "- Download the .rpm package from here: https://www.neuron.yale.edu/neuron/download\n",
    "- Install it with: \n",
    "    `alien -i nrn_...*package*` (Note that the .deb package did not work out, and neither did the installation using rpm directly)\n",
    "- Edit the .bashrc file by adding the following lines: \n",
    "\n",
    "    `#Added for neuron\n",
    "    export PYTHONPATH=\"${PYTHONPATH}:/usr/local/nrn/lib/python/\" `\n",
    "    \n",
    "    (first check that this path is actually where it got installed by going to the folder and see whether `python -c 'import neuron'` tells you about your NEURON version or whether there ain't no module called neuron.\n",
    "\n",
    "\n",
    "http://www.davison.webfactional.com/notes/hoc-to-python-bulbnet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-08T11:06:59.934099Z",
     "start_time": "2017-11-08T11:06:59.925139Z"
    },
    "collapsed": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pickle \n",
    "import warnings\n",
    "import neuron\n",
    "import sys\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "#! echo $PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run BREPpy.py\n",
    "\n",
    "#Todo: Read in from command line for int or bool parameters.\n",
    "b = Brep()\n",
    "b.init_from_script(['--config_fn','./input_files/Parameters.hoc'])\n",
    "b.read_in_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Checking out the output of the original BREP program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File read-in procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-08T11:07:00.164457Z",
     "start_time": "2017-11-08T11:06:59.936000Z"
    },
    "code_folding": [],
    "collapsed": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "##filenames and input paths for the different files.\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "path_4 = os.getcwd()+'/output_25/'\n",
    "path_16 = os.getcwd()+'/output_16/'\n",
    "path_full = os.getcwd()+'/output_full_def/'\n",
    "path_old = os.getcwd()+'/output_1/'\n",
    "path_ivan = os.getcwd()+'/brep-ivan/'\n",
    "\n",
    "path = path_full\n",
    "\n",
    "fns = OrderedDict ()\n",
    "fns['aa_go_dist']='AAtoGoCdistances.dat'\n",
    "fns['aa_go_segs']='AAtoGoCsegments.dat'\n",
    "fns['aa_go_source']='AAtoGoCsources.dat'\n",
    "fns['aa_go_target']='AAtoGoCtargets.dat'\n",
    "\n",
    "fns['gran_coord'] ='GCcoordinates.sorted.dat'       \n",
    "fns['gran_t_coord']='GCTcoordinates.sorted.dat'\n",
    "    \n",
    "fns['go_coord']='GoCcoordinates.sorted.dat'\n",
    "fns['go_basd_coord']='GoCbdendcoordinates.sorted.dat'\n",
    "fns['go_apical_coord']='GoCadendcoordinates.sorted.dat'\n",
    "fns['go_axon_coord']='GoCaxoncoordinates.sorted.dat'\n",
    "fns['go_dist']='GoCdistances.dat' \n",
    "       \n",
    "fns['go_go_dist']='GoCtoGoCdistances.dat'\n",
    "fns['go_go_source']='GoCtoGoCsources.dat'\n",
    "fns['go_go_target']='GoCtoGoCtargets.dat'\n",
    "fns['go_go_gap_dist']='GoCtoGoCgapdistances.dat'\n",
    "fns['go_go_gap_source']='GoCtoGoCgapsources.dat'\n",
    "fns['go_go_gap_target']='GoCtoGoCgaptargets.dat'\n",
    "\n",
    "fns['pf_go_dist']='PFtoGoCdistances.dat'\n",
    "fns['pf_go_seg']='PFtoGoCsegments.dat'\n",
    "fns['pf_go_source']='PFtoGoCsources.dat'\n",
    "fns['pf_go_target']='PFtoGoCtargets.dat'\n",
    "\n",
    "#for k,v in fns.items():\n",
    "##    print (k)\n",
    "#a = import_csv(in_f)\n",
    "#rr = read_in_coordfile (in_goba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-08T11:07:00.254774Z",
     "start_time": "2017-11-08T11:07:00.166811Z"
    },
    "code_folding": [
     2
    ],
    "collapsed": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#def import_csv (fn):\n",
    "def read_in_coordfile (fn, parse_ignore = True):\n",
    "    res = []\n",
    "    with open (fn, newline = '') as f:\n",
    "        rr = csv.reader(f, delimiter = ' ')\n",
    "        err = []\n",
    "        for line in rr:\n",
    "            ar = []\n",
    "            for j in range(len(line)):\n",
    "                try: ar.append(float(line[j]))\n",
    "                except: err.append(line[j])\n",
    "            res.append(np.asarray(ar))\n",
    "    if len(err)> 0 and not parse_ignore: print ('Could not parse on {} instances: {}'.format(len(err), set(err)))\n",
    "    return np.asarray(res)\n",
    "\n",
    "#reshape\n",
    "def coord_reshape (dat):\n",
    "    dat = dat.reshape([dat.shape[0], int(dat.shape[1]/3),3])\n",
    "    return dat\n",
    "\n",
    "#rr = read_in_coordfile(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview over the different output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-07T13:14:08.220766Z",
     "start_time": "2017-11-07T13:13:31.734901Z"
    },
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# An overview over the different files that BREP produces and the comparison between two different files\n",
    "for k, v in fns.items():\n",
    "    print ('Read in file: ', v)\n",
    "    c_p = path+v\n",
    "    cur = read_in_coordfile(c_p)\n",
    "    \n",
    "    #c_p2 = os.getcwd()+'/output_2/'+v\n",
    "    #cur2 = read_in_coordfile(c_p2)\n",
    "\n",
    "    print ('Shape 1 is: ', cur.shape)\n",
    "    #print ('Shape 2 is: ', cur2.shape)\n",
    "    \n",
    "    print ('First elements in 1 are:', cur.flatten()[:15])\n",
    "    #print ('First elements in 2 are:', cur2.flatten()[:15])\n",
    "    \n",
    "    print (' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T09:35:56.205531Z",
     "start_time": "2017-11-06T09:35:56.203216Z"
    }
   },
   "source": [
    "### Connectivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-07T13:20:34.404796Z",
     "start_time": "2017-11-07T13:20:33.482908Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = path_full\n",
    "gap_t = read_in_coordfile(path + fns['go_go_gap_target'])\n",
    "pf_t = read_in_coordfile(path + fns['pf_go_target'])\n",
    "aa_t = read_in_coordfile(path+fns['aa_go_target'])\n",
    "gg_t = read_in_coordfile(path+fns['go_go_target'])\n",
    "\n",
    "\n",
    "def target_stats (dat, name = ''):\n",
    "    un, counts = np.unique(dat, return_counts=True)\n",
    "    print (name)\n",
    "    print ('Connections per cell: ', round(np.mean(counts),2),'+/-', round(np.std(counts), 2), ', range ', min(counts),'-', max(counts))\n",
    "\n",
    "target_stats(gg_t, 'Golgi to Golgi:')\n",
    "target_stats(aa_t, 'AA to Golgi:')\n",
    "target_stats(pf_t, 'Parallel Fiber to Golgi:')\n",
    "target_stats(gap_t, 'Golgi to Golgi gap junctions:')\n",
    "\n",
    "print(\n",
    "'''\n",
    "Here are the paper values as a comparison:\n",
    "Golgi to Golgi:\n",
    "Connections per cell:  144.85 +/- 36.88 , range  72 - 195\n",
    "AA to Golgi:\n",
    "Connections per cell:  554 +/- 302 , range  55 - 1245\n",
    "Parallel Fiber to Golgi:\n",
    "Connections per cell:  4759 +/- 1037, range 2512-6582\n",
    "Golgi to Golgi gap junctions:\n",
    "Connections per cell:  13.7 +/- 4.6 , range  1-31''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Golgi-Granule interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-07T13:20:49.081253Z",
     "start_time": "2017-11-07T13:20:37.693147Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Go_ori = read_in_coordfile(path+fns['go_coord']) #soma points of granule cells\n",
    "Gr_ori = read_in_coordfile(path+fns['gran_coord']) #soma points of Golgi cells\n",
    "GrT_ori = read_in_coordfile(path+fns['gran_t_coord'])\n",
    "pf_t = read_in_coordfile(path+fns['pf_go_target']) #the Golgi cell ID\n",
    "pf_s = read_in_coordfile(path+fns['pf_go_source']) #number = the parallel fiber ID\n",
    "aa_t = read_in_coordfile(path+fns['aa_go_target'])\n",
    "aa_s = read_in_coordfile(path+fns['aa_go_source'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-07T13:20:50.253884Z",
     "start_time": "2017-11-07T13:20:49.103371Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#n_Go = 200\n",
    "#n_Gr = 10000\n",
    "\n",
    "#print (int(max(pf_s)))\n",
    "#print (max(pf_t))\n",
    "\n",
    "def so_tar_sets (so, tar, n_so = -1, n_tar = -1):\n",
    "    '''Takes two lists of sources and targets (must have same length), and constructs a list of set from it.\n",
    "    Output = source-> target, target -> source'''\n",
    "    if n_so<0: n_so = int(max(so)+1)\n",
    "    if n_tar<0: n_tar = int(max(tar)+1)\n",
    "    so_tar = [set() for i in range(n_so)]\n",
    "    tar_so = [set() for i in range(n_tar)]\n",
    "    for s, t in zip (so, tar):\n",
    "        so_tar[int(s)].add(int(t))\n",
    "        tar_so[int(t)].add(int(s))\n",
    "    return so_tar, tar_so\n",
    "\n",
    "#go_gr = [set() for i in range(n_Go)]\n",
    "#gr_go = [set() for i in range(n_Gr)]\n",
    "\n",
    "#for s,t in zip(pf_s, pf_t):\n",
    "#    go_gr[int(t)].add(int(s))\n",
    "#    gr_go[int(s)].add(int(t))\n",
    "    \n",
    "gr_go, go_gr = so_tar_sets(pf_s, pf_t)\n",
    "\n",
    "print (gr_go[:10])\n",
    "print (go_gr[:10])\n",
    "\n",
    "ls= [len(gr_go[i]) for i in range(len(gr_go))]\n",
    "print (np.argmax(ls))\n",
    "\n",
    "ks= [len(go_gr[i]) for i in range(len(go_gr))]\n",
    "print (np.argmax(ks))\n",
    "\n",
    "#print (gogr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-07T14:18:33.975482Z",
     "start_time": "2017-11-07T14:18:32.706302Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gr_iv = read_in_coordfile(path_ivan + fns['gran_coord'])\n",
    "grt_iv = read_in_coordfile(path_ivan + fns['gran_t_coord'])\n",
    "go_iv = read_in_coordfile(path_ivan + fns['go_coord'])\n",
    "\n",
    "pop_1 =  gr_iv# small dots\n",
    "pop_2 =  go_iv# big dots\n",
    "pop_3 = grt_iv\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "plot3d(ax, pop_1, 'k.', markersize=0.4)\n",
    "plot3d(ax, pop_2, 'ro')\n",
    "plot3d(ax, pop_3, 'b.', markersize=0.4)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "for i, [j, k, tit] in enumerate([[0,1, 'x-y plane'], [1,2, 'y-z plane'], [0,2, 'x-z plane']]):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.plot(pop_1[:,j], pop_1[:,k],  'k.', markersize=0.4)\n",
    "    plt.plot(pop_2[:,j], pop_2[:,k],  'ro')\n",
    "    plt.plot(pop_3[:,j], pop_3[:,k],  'b.', markersize=0.4)\n",
    "\n",
    "print (len(go_iv))\n",
    "print (len(gr_iv))\n",
    "\n",
    "x_go = go_iv[:,0]\n",
    "plt.figure()\n",
    "plt.plot(np.sort(x_go))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-07T14:01:11.710066Z",
     "start_time": "2017-11-07T14:01:11.570975Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! ls brep-ivan/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-07T14:04:09.992546Z",
     "start_time": "2017-11-07T14:04:08.394509Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#n = 9# 3d plot\n",
    "ks= [len(go_gr[i]) for i in range(len(go_gr))]\n",
    "ls= [len(gr_go[i]) for i in range(len(gr_go))]\n",
    "\n",
    "pop_1 =  gr_iv# small dots\n",
    "pop_2 =  go_iv# big dots\n",
    "pts_1 = Go_ori[np.array(list(gr_go[np.argmax(ls)]))]\n",
    "\n",
    "pts_2 = Gr_ori[np.array(list(go_gr[np.argmax(ks)]))]#[np.array(Gid_aa[n]),:]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "plot3d(ax, pop_1, 'k.', markersize=0.2)\n",
    "plot3d(ax, pop_2, 'ro')\n",
    "plot3d(ax, pts_1, 'go')\n",
    "#ax.plot(all_pts[0,0],all_pts[0,1],all_pts[0,2], 'go')\n",
    "plot3d(ax, pts_2, 'bo', markersize=1.0)\n",
    "plt.axis('equal')\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "for i, [j, k, tit] in enumerate([[0,1, 'x-y plane'], [1,2, 'y-z plane'], [0,2, 'x-z plane']]):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.plot(pop_1[:,j], pop_1[:,k],  'k.', markersize=0.2)\n",
    "    plt.plot(pop_2[:,j], pop_2[:,k],  'ro')\n",
    "    plt.plot(pts_1[:,j], pts_1[:,k], 'go')\n",
    "    plt.plot(pts_2[:,j], pts_2[:,k], 'bo', markersize=4.0)\n",
    "    plt.axis('equal')\n",
    "    plt.title(tit)\n",
    "    \n",
    "plt.figure(figsize=(15,5))\n",
    "for i, [j, k, tit] in enumerate([[0,1, 'x-y plane'], [1,2, 'y-z plane'], [0,2, 'x-z plane']]):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.plot(pop_1[:,j], pop_1[:,k],  'k.', markersize=0.3)\n",
    "    plt.plot(pop_2[:,j], pop_2[:,k],  'ro')\n",
    "    plt.plot(pts_1[:,j], pts_1[:,k], 'go')\n",
    "    plt.plot(pts_2[:,j], pts_2[:,k], 'bo', markersize=2.0)\n",
    "    plt.title(tit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-07T08:11:40.155309Z",
     "start_time": "2017-11-07T08:11:37.341895Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#gr and grt relation: grt = gr + [0, 0, 200]\n",
    "gr_c = read_in_coordfile(path+fns['gran_coord'])\n",
    "grt_c = read_in_coordfile(path+fns['gran_t_coord'])\n",
    "print (sum (gr_c-grt_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Golgi-Golgi interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-07T14:30:30.507961Z",
     "start_time": "2017-11-07T14:30:28.913546Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## golgi-golgi interactions\n",
    "src = read_in_coordfile(path+fns['go_go_source'])\n",
    "tar = read_in_coordfile(path+fns['go_go_target'])\n",
    "dis = read_in_coordfile(path+fns['go_go_dist'])\n",
    "coord = read_in_coordfile(path+fns['go_coord'])\n",
    "\n",
    "res_n = np.zeros(100)\n",
    "for i in range(100):\n",
    "    #res_n[i] = np.linalg.norm(coord[int(tar[i]),:]-coord[int(src[i]),:])\n",
    "    res_n[i] = (sum((coord[int(tar[i]),:]-coord[int(src[i]),:])**2)**0.5)\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "# Checking out the connectivities per GC\n",
    "#n_Go = 200\n",
    "#source files\n",
    "def conrad_hist (dis, tit ='connectivity radius'):\n",
    "    plt.figure()\n",
    "    aux = plt.hist(dis, bins = 100)\n",
    "    plt.xlabel('radius')\n",
    "    plt.ylabel('number of connections')\n",
    "    plt.title (tit)\n",
    "    \n",
    "conrad_hist(dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-07T14:30:34.647008Z",
     "start_time": "2017-11-07T14:30:33.978110Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "src_g = read_in_coordfile(path+fns['go_go_gap_source'])\n",
    "tar_g = read_in_coordfile(path+fns['go_go_gap_target'])\n",
    "dis_g = read_in_coordfile(path+fns['go_go_gap_dist'])\n",
    "conrad_hist(dis_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notable things\n",
    "- BREP does not seem to take into account the densities from the config file. It just uses the number of Golgi/Granule cells that are defined in its default. The parameters NumGC or NumGoC which is defined in the input dict does not exist in the Parameter.hoc file at all.\n",
    "- BREP does not seem to check for or find out if there is a number of GCT points that is not related to the number of GC points. It just simulates GC points with aa independently of the GCT points that are the origin of the PF\n",
    "- The connectivity also does not correspond "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Golgi cells\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation\n",
    "Shitty here, look at the Check-out-Golgi notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-08T11:07:00.380827Z",
     "start_time": "2017-11-08T11:07:00.256365Z"
    },
    "collapsed": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def gen_dendrites (som, c_r, c_h, c_m, c_std, c_sp, col = 'kx', plot_fig = False):\n",
    "    '''Generates dendrites as described in the paper:\n",
    "    som = coordinates of somata\n",
    "    c_r = maximal radius of cone\n",
    "    c_h = height of cone\n",
    "    c_m = mean angle for each dendrite (number of elements = number of dendrites per cell)\n",
    "    c_std = standard deviation (degree) for the angle of the dendrite\n",
    "    c_sp = spacing between the points\n",
    "    col = color if plot function is enabled\n",
    "    plot_fig = plot the results?\n",
    "    Returns a list of lists containing arrays with the coordinates of the dendrites\n",
    "    '''\n",
    "    c_n = int(np.linalg.norm([c_r, c_h])/c_sp) #number of points per dendrite\n",
    "    c_gr = np.linspace(0,1,c_n)*np.ones((3, c_n)) #linspace grid between 0 and 1 with c_n elements\n",
    "    b_res = []\n",
    "    for i in range(len(som)): #each cell\n",
    "        som_c = som[i,:]\n",
    "        d_res = []\n",
    "        for cc_m in c_m: #each dendrite\n",
    "            ep_ang = (np.random.randn()*c_std + cc_m)*np.pi/180 #angle\n",
    "            pt = ([np.sin(ep_ang)*c_r, np.cos(ep_ang)*c_r, c_h])*c_gr.T #coordinates of the dendrite = endpoint*grid \n",
    "            if plot_fig: ax.plot(pt[:,0], pt[:,1], pt[:,2], col);\n",
    "            d_res.append(pt+som_c) \n",
    "        b_res.append(d_res)\n",
    "    return b_res\n",
    "\n",
    "a_h = 332.0\n",
    "a_r= 100.0\n",
    "b_h = -6.0\n",
    "b_r = 60.0\n",
    "a_m = [30.0, 120.0]\n",
    "b_m = [-20.0, -240.0]\n",
    "b_std = 10\n",
    "a_std = 10\n",
    "a_sp = 6.6\n",
    "b_sp = 14.4\n",
    "\n",
    "#coord = read_in_coordfile(path+fns['go_coord']) #soma points\n",
    "\n",
    "#a_dend = gen_dendrites(coord, a_r, a_h, a_m, a_std, a_sp, 'gx')\n",
    "#b_dend = gen_dendrites(coord, b_r, b_h, b_m, b_std, b_sp, 'kx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize Golgi cells\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "\n",
    "#read in\n",
    "coord = read_in_coordfile(path+fns['go_coord'])\n",
    "apical = read_in_coordfile(path+fns['go_apical_coord'])\n",
    "basal = read_in_coordfile(path+fns['go_basd_coord'])\n",
    "axon = read_in_coordfile(path+fns['go_axon_coord'])\n",
    "new_ap = read_in_coordfile('new_apical.dat', parse_ignore=False)\n",
    "new_bas = read_in_coordfile('new_basal.dat', parse_ignore=False)\n",
    "new_ax = read_in_coordfile('new_axon.dat', parse_ignore=False)\n",
    "\n",
    "\n",
    "apical = apical.reshape([apical.shape[0],int(apical.shape[1]/3),3])\n",
    "basal = basal.reshape([basal.shape[0],int(basal.shape[1]/3),3])\n",
    "axon = axon.reshape([axon.shape[0],int(axon.shape[1]/3),3])\n",
    "print (axon.shape)\n",
    "new_ap = coord_reshape(new_ap)\n",
    "new_bas = coord_reshape(new_bas)\n",
    "print( new_ax.shape)\n",
    "new_ax = coord_reshape(new_ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-31T16:20:27.145356Z",
     "start_time": "2017-10-31T16:20:27.123285Z"
    },
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dendrite spacing\n",
    "ap = apical[1,:]\n",
    "bas = basal[1,:]\n",
    "resa = [np.linalg.norm(ap[j,:]-ap[j+1,:]) for j in range(len(ap)-1)]\n",
    "resb = [np.linalg.norm(bas[j,:]-bas[j+1,:]) for j in range(len(bas)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "ns = np.arange(1) #neurons to be plotted.\n",
    "\n",
    "plot_somata = True\n",
    "plot_apical = 0\n",
    "plot_basal = 0\n",
    "plot_axon = 0\n",
    "plot_new_ap = 0\n",
    "plot_new_bas  = 0\n",
    "plot_new_ax = 1\n",
    "overlay = 0\n",
    "\n",
    "options= [\n",
    "    (apical, plot_apical, 'kx'),\n",
    "    (basal, plot_basal, 'gx'), \n",
    "    (axon, plot_axon, 'r.'), \n",
    "    (new_ap, plot_new_ap, 'cx'),\n",
    "    (new_bas, plot_new_bas, 'mx'),\n",
    "    (new_ax, plot_new_ax, 'y.')]\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "if plot_somata: \n",
    "    if not overlay: ax.plot(coord[ns,0], coord[ns,1], coord[ns,2], 'bo')\n",
    "    else: ax.plot ([0],[0],[0],'bo')\n",
    "\n",
    "#plot dendrites and axon.\n",
    "for pts, yn, col in options:\n",
    "    for i in ns:\n",
    "        if yn:\n",
    "            if overlay: pt = pts[i,:,:]-coord[i,:]\n",
    "            else: pt = pts[i,:,:]\n",
    "            ax.plot(pt[:,0], pt[:,1], pt[:,2], col)\n",
    "\n",
    "#ax.view_init(30,180)\n",
    "proj2D = True\n",
    "if proj2D:\n",
    "    plt.figure()\n",
    "    for pts, yn, col in options:\n",
    "        for i in ns:\n",
    "            if yn:\n",
    "                if overlay: pt = pts[i,:,:]-coord[i,:]\n",
    "                else: pt = pts[i,:,:]\n",
    "                plt.plot(pt[:,0], pt[:,1], col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-31T10:56:34.126245Z",
     "start_time": "2017-10-31T10:56:34.122943Z"
    }
   },
   "source": [
    "### Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-07T15:58:45.556137Z",
     "start_time": "2017-11-07T15:58:23.883889Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "goc = read_in_coordfile(path_ivan+fns['go_coord'])\n",
    "\n",
    "res = np.zeros((40000, 3))\n",
    "for i in range(200):\n",
    "    for j in range(200):\n",
    "        res[i*200+j,:] = goc[i,:]-coord[j,:]\n",
    "#dist = [coord[i,:]-coord[j,:] for i,j in range(200)]\n",
    "dist = read_in_coordfile(path+fns['go_dist'])\n",
    "\n",
    "#print (res[1:100,:] + dist[:99,:])\n",
    "#the distances file just contains all possible differences betwween the different Golgi cells, rounded in an inconsistant way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-31T10:57:31.241861Z",
     "start_time": "2017-10-31T10:57:31.239094Z"
    }
   },
   "source": [
    "### Golgi-Golgi Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "res_n = np.zeros(100)\n",
    "for i in range(100):\n",
    "    #res_n[i] = np.linalg.norm(coord[int(tar[i]),:]-coord[int(src[i]),:])\n",
    "    res_n[i] = (sum((coord[int(tar[i]),:]-coord[int(src[i]),:])**2)**0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Granule cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-08T11:07:00.506762Z",
     "start_time": "2017-11-08T11:07:00.382385Z"
    },
    "collapsed": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "aa_length = 200.0\n",
    "aa_step = 50.0 #this might have to be adapted if the length is not divisable by step\n",
    "pf_length = 1000.0\n",
    "pf_step = 7.5\n",
    "\n",
    "\n",
    "def gen_aa_and_pf (coo, aa_length, aa_step, pf_length, pf_step, plot = False):\n",
    "    \n",
    "    if plot:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.gca(projection='3d')\n",
    "    \n",
    "    aa_nd = int(aa_length/aa_step) + 1 \n",
    "    aa_sp = np.linspace(0, aa_length, aa_nd)\n",
    "\n",
    "    pf_nd = int(2*pf_length/pf_step) + 1\n",
    "    pf_sp = np.linspace(-pf_length, pf_length, pf_nd)\n",
    "\n",
    "    aa_dots = np.zeros((len(coo), aa_nd, 3))\n",
    "    pf_dots = np.zeros((len(coo), pf_nd, 3))\n",
    "    for i, som in enumerate(coo):\n",
    "        aa_dots[i] = np.ones((aa_nd, 3))*som\n",
    "        aa_dots[i,:,2] = aa_dots[i,:,2] + aa_sp\n",
    "        pf_dots[i] = np.ones((pf_nd,3))*aa_dots[i,-1, :]\n",
    "        pf_dots[i,:,0] = pf_dots[i,:,0] + pf_sp\n",
    "        if plot:\n",
    "            plot3d(ax, aa_dots[i], 'ko', markersize=1.0)\n",
    "            plot3d(ax, pf_dots[i], 'r.', markersize=1.0)\n",
    "    return aa_dots, pf_dots\n",
    "#an idea: can we not use a wider, but more random spacing? Like that there are less points, but the connectio\n",
    "\n",
    "\n",
    "def gen_aa_random (coo, mol_range  = [230, 430]):\n",
    "    aa_dots = np.array([np.array([coo[i], coo[i]]) for i in range(len(coo))])\n",
    "    aa_dots[:,1,2] = np.random.uniform(mol_range[0], mol_range[1], len(aa_dots[:,1,2]))\n",
    "    return aa_dots\n",
    "\n",
    "def gen_aa_fixed (coo, aa_length =200):\n",
    "    aa_dots = np.array([np.array([coo[i], coo[i]]) for i in range(len(coo))])\n",
    "    aa_dots[:,1,2] = aa_dots[:,1,2] + aa_length\n",
    "    return aa_dots\n",
    "\n",
    "def gen_pf_from_aa (aa_dots, pf_length):\n",
    "    ''' '''\n",
    "    pf_dots = aa_dots.copy()\n",
    "    pf_dots[:,0,2] = pf_dots[:,1,2] #z axis shall be the same\n",
    "    pf_dots[:,0,0] = pf_dots[:,0,0] - pf_length\n",
    "    pf_dots[:,1,0] = pf_dots[:,1,0] + pf_length\n",
    "    \n",
    "    return pf_dots\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T11:22:17.195380Z",
     "start_time": "2017-11-03T11:22:15.339085Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 3D Test\n",
    "coo = Gr_co #[:10,:]\n",
    "aa_d, pf_d = gen_aa_and_pf (coo, aa_length, aa_step, pf_length, pf_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T11:22:23.781372Z",
     "start_time": "2017-11-03T11:22:22.200654Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#2D Test\n",
    "aa_d2 = gen_aa_random (coo, mol_range  = [230, 430])\n",
    "aa_d3 = gen_aa_fixed (coo, aa_length =200)\n",
    "\n",
    "pf_d2 = gen_pf_from_aa (aa_d2, pf_length)\n",
    "\n",
    "#aa_d2, pf_d2 = gen_pts_for_2dt (coo, aa_length, pf_length)\n",
    "print (pf_d2.shape)\n",
    "print (aa_d2.shape)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "for i, [j, k, tit] in enumerate([[0,1, 'x-y plane'], [1,2, 'y-z plane'], [0,2, 'x-z plane']]):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.plot(aa_d2 [:,0,j], aa_d2[:,0,k],  'k.', markersize=0.2)\n",
    "    plt.plot(aa_d2 [:,1,j], aa_d2[:,1,k],  'g.', markersize=0.2)\n",
    "    plt.plot(pf_d2 [:,1,j], pf_d2[:,1,k],  'r.', markersize=0.2)\n",
    "    plt.plot(pf_d2 [:,0,j], pf_d2[:,0,k],  'm.', markersize=0.2)\n",
    "    plt.axis('equal')\n",
    "    plt.title(tit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-08T11:07:00.632289Z",
     "start_time": "2017-11-08T11:07:00.508280Z"
    },
    "collapsed": false,
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "80000\n"
     ]
    }
   ],
   "source": [
    "# Somata generating method \n",
    "\n",
    "#Dimensions of the Granule cell layer\n",
    "Gc_x = 300\n",
    "Gc_y = 70\n",
    "Gc_z = 200\n",
    "\n",
    "n_Go = int(2000*Gc_x*Gc_y/700/1500)\n",
    "n_Gr = 2000*n_Go\n",
    "print (n_Go)\n",
    "print (n_Gr)\n",
    "\n",
    "def get_cell_loc (n_cell, Gc_x, Gc_y, Gc_z):\n",
    "    # get spacing for grid:\n",
    "    vol_c = Gc_x*Gc_y*Gc_z/n_cell\n",
    "    sp_def = vol_c**(1/3)/2\n",
    "    \n",
    "    #first get a few too many\n",
    "    gr = np.asarray([[i,j,k] \n",
    "                     for i in np.arange(0, Gc_x, 2*sp_def)   \n",
    "                     for j in np.arange(0, Gc_y, 2*sp_def) \n",
    "                     for k in np.arange(0, Gc_z, 2*sp_def)])\n",
    "\n",
    "    grc = gr + np.random.randn(*gr.shape)*sp_def\n",
    "    #then remove the ones that lie most outside to get the correct number of cells\n",
    "    \n",
    "    lower = grc.T.ravel()\n",
    "    upper = -(grc-[Gc_x, Gc_y, Gc_z]).T.ravel()\n",
    "    most_out_idx = np.mod(np.argsort(np.concatenate((lower,upper))), len(grc))\n",
    "    del_el = len(grc) - n_cell # number of elements to be deleted\n",
    "    n_del = del_el\n",
    "    \n",
    "    while len(np.unique(most_out_idx[:n_del])) < del_el:\n",
    "        n_del = n_del + del_el - len(np.unique(most_out_idx[:n_del]))\n",
    "        \n",
    "    grc = grc[np.setdiff1d(np.arange(len(grc)), most_out_idx[:n_del]),:]\n",
    "    return grc\n",
    "\n",
    "\n",
    "def plot3d (ax, dat, *args, **kwargs):\n",
    "    ax.plot(dat[:,0], dat[:,1], dat[:,2], *args, **kwargs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T11:21:49.393277Z",
     "start_time": "2017-11-03T11:21:47.900966Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the two populations\n",
    "Gr_co = get_cell_loc(n_Gr, Gc_x, Gc_y, Gc_z)\n",
    "Go_co = get_cell_loc(n_Go, Gc_x, Gc_y, Gc_z)\n",
    "\n",
    "# 3d plot\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "plot3d(ax, Gr_co, 'k.', markersize=0.2)\n",
    "plot3d(ax, Go_co, 'ro')\n",
    "\n",
    "#projections\n",
    "plt.figure(figsize=(15,5))\n",
    "for i, [j, k, tit] in enumerate([[0,1, 'x-y plane'], [1,2, 'y-z plane'], [0,2, 'x-z plane']]):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.plot(Gr_co[:,j], Gr_co[:,k],  'k.', markersize=0.2)\n",
    "    plt.plot(Go_co[:,j], Go_co[:,k],  'ro')\n",
    "    plt.axis('equal')\n",
    "    plt.title(tit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assembling the points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-08T11:07:00.749783Z",
     "start_time": "2017-11-08T11:07:00.635145Z"
    },
    "collapsed": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree as kdt\n",
    "\n",
    "#General slice information\n",
    "Gc_x = 150\n",
    "Gc_y = 30\n",
    "Gc_z = 200\n",
    "#Golgi cell dendrite parameters\n",
    "a_h = 332.0\n",
    "a_r= 100.0\n",
    "b_h = -6.0\n",
    "b_r = 60.0\n",
    "a_m = [30.0, 120.0]\n",
    "b_m = [-20.0, -240.0]\n",
    "b_std = 10\n",
    "a_std = 10\n",
    "a_sp = 6.6\n",
    "b_sp = 14.4\n",
    "#Granule cell parameters\n",
    "aa_length = 200.0\n",
    "aa_step = 50.0 #this might have to be adapted if the length is not divisable by step\n",
    "pf_length = 1000.0\n",
    "pf_step = 7.5\n",
    "\n",
    "#number of cells (use densities later!)\n",
    "Go_dens  = 9.5e-6 # from the paper: n_cells/ym³\n",
    "Gr_Go_ratio = 400\n",
    "\n",
    "\n",
    "def dend_to_default_format (dend):\n",
    "    '''change format of the lists from the gen_dendrites function to cells*points*coordinates'''\n",
    "    dd = np.asarray([np.concatenate((dend[i][0], dend[i][1])) for i in range(len(dend))])\n",
    "    return dd\n",
    "\n",
    "# !! Relies on global variables\n",
    "def full_pop (Gc_x, Gc_y, Gc_z=200, dim2 = True, random_aa = False):\n",
    "    ''' will give you a full population including points for a given size, in order to make generation easier\n",
    "    '''\n",
    "    n_Go = int (Go_dens*Gc_x*Gc_y*Gc_z)\n",
    "    n_Gr = Gr_Go_ratio*n_Go\n",
    "    print ('Number of Golgi cells:',n_Go)\n",
    "    print ('Number of Granule cells:', n_Gr)\n",
    "    # get the two populations4\n",
    "    Gr_co = get_cell_loc(n_Gr, Gc_x, Gc_y, Gc_z)\n",
    "    Go_co = get_cell_loc(n_Go, Gc_x, Gc_y, Gc_z)\n",
    "    # get the dendrites\n",
    "    a_dend = dend_to_default_format(gen_dendrites(Go_co, a_r, a_h, a_m, a_std, a_sp, 'gx'))\n",
    "    b_dend = dend_to_default_format(gen_dendrites(Go_co, b_r, b_h, b_m, b_std, b_sp, 'kx'))\n",
    "    \n",
    "    if dim2:\n",
    "        if random_aa: aa_d = gen_aa_random (Gr_co, mol_range  = [230, 430])\n",
    "        else: aa_d = gen_aa_fixed (Gr_co, aa_length =200)\n",
    "        pf_d = gen_pf_from_aa (aa_d, pf_length)\n",
    "    else: aa_d, pf_d = gen_aa_and_pf(Gr_co, aa_length, aa_step, pf_length, pf_step)\n",
    "        \n",
    "    return (Gr_co, Go_co, a_dend, b_dend,  aa_d, pf_d)\n",
    "    \n",
    "def flatten_cells (dat):\n",
    "    return dat.reshape(dat.shape[0]*dat.shape[1],dat.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T11:25:59.748058Z",
     "start_time": "2017-11-03T11:25:59.594648Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_Go = int (Go_dens*Gc_x*Gc_y*Gc_z)\n",
    "n_Gr = Gr_Go_ratio*n_Go\n",
    "print (n_Go)\n",
    "print (n_Gr)\n",
    "\n",
    "# get the two populations4\n",
    "Gr_co = get_cell_loc(n_Gr, Gc_x, Gc_y, Gc_z)\n",
    "Go_co = get_cell_loc(n_Go, Gc_x, Gc_y, Gc_z)\n",
    "\n",
    "# get the dendrites\n",
    "a_dend = dend_to_default_format(gen_dendrites(Go_co, a_r, a_h, a_m, a_std, a_sp, 'gx'))\n",
    "b_dend = dend_to_default_format(gen_dendrites(Go_co, b_r, b_h, b_m, b_std, b_sp, 'kx'))\n",
    "\n",
    "# get aa and pf\n",
    "aa_d, pf_d = gen_aa_and_pf(Gr_co, aa_length, aa_step, pf_length, pf_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKL implementation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T10:21:56.675119Z",
     "start_time": "2017-11-03T10:21:56.648191Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Gr_co, Go_co, a_dend, b_dend,  aa_d, pf_d = full_pop (15, 10, Gc_z=200)\n",
    "kt_aa = kdt(flatten_cells(aa_d))\n",
    "kt_pf = kdt(flatten_cells(pf_d))\n",
    "# 4 Golgi cells -> around 40-50 s\n",
    "# 8 Golgis -> around 130 s -> about 4.3e6 pts --> if we represent all aa with 5 pts, this is feasible (will be around 4e6 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-02T14:17:41.129792Z",
     "start_time": "2017-11-02T14:17:27.429379Z"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# connection radius\n",
    "c_rad_aa = 30.0\n",
    "c_rad_pf = 5.0\n",
    "#number of points per granule cell \n",
    "n_pt_aa = aa_d.shape[1]\n",
    "n_pt_pf = pf_d.shape[1]\n",
    "\n",
    "res_aa_a = []\n",
    "for i, pt in enumerate(flatten_cells(a_dend)):\n",
    "    warnings.simplefilter('ignore')\n",
    "    ind, = kt_aa.query_radius(pt, r= c_rad_aa)\n",
    "    res_aa_a.append(np.unique((np.floor(ind/n_pt_aa)).astype('int')))\n",
    "    \n",
    "res_aa_b = []\n",
    "for i, pt in enumerate(flatten_cells(b_dend)):\n",
    "    warnings.simplefilter('ignore')\n",
    "    ind, = kt_aa.query_radius(pt, r= c_rad_aa)\n",
    "    res_aa_b.append(np.unique((np.floor(ind/n_pt_aa)).astype('int')))\n",
    "    \n",
    "\n",
    "    \n",
    "res_pf_a = []\n",
    "gr_f = []\n",
    "for i, pt in enumerate(flatten_cells(a_dend)):\n",
    "    warnings.simplefilter('ignore')\n",
    "    ind, = kt_pf.query_radius(pt, r= c_rad_pf)\n",
    "    if len(ind) > 0: gr_f.append(i)\n",
    "    res_pf_a.append(np.unique((np.floor(ind/n_pt_pf)).astype('int')))\n",
    "    \n",
    "res_pf_b = []\n",
    "for i, pt in enumerate(flatten_cells(b_dend)):\n",
    "    warnings.simplefilter('ignore')\n",
    "    ind, = kt_pf.query_radius(pt, r= c_rad_pf)\n",
    "    if len(ind) > 0: print (i)\n",
    "    res_pf_b.append(np.unique((np.floor(ind/n_pt_pf)).astype('int')))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-02T11:05:03.572127Z",
     "start_time": "2017-11-02T11:05:03.567118Z"
    },
    "collapsed": false
   },
   "source": [
    "### 2D SKL implementation\n",
    "\n",
    "**Idea behind this:**\n",
    "It seems somehow contraintuitive to represent a long line by loads of three-dimensional points.\n",
    "Instead, it could be much more efficient to represent the line as a dot (if necessary, adjust coordinate system) and do a 2-dimensional nn search. Cut off the Golgi cells that lie outside (In that case, the tree consists of the Golgi dendrites)\n",
    "This could come in especially handy for the PF. \n",
    "The AA are represented by far less points, so in order to make it possible that they might not just be straight lines along the z axis, the tree could be constructed from them (4-5 pts), and then for the Golgi dendrites the search is performed.\n",
    "\n",
    "**Possible Caveats:**\n",
    "- The ends are not round\n",
    "- Small random displacements are not possible\n",
    "- For a strongly elongated architecture, it is more complicated, as the number of Golgi cells that are considered uselessly increases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T15:22:33.817326Z",
     "start_time": "2017-11-06T15:22:32.964099Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get population\n",
    "Gr_co, Go_co, a_dend, b_dend,  aa_d, pf_d = full_pop (1500*0.1**0.5, 700*0.1**0.5, Gc_z=200, dim2 = True)\n",
    "#get the right dendrites\n",
    "\n",
    "# To think about: for the pf only do the search if the points are in the molecular layer.\n",
    "\n",
    "dends = np.concatenate((flatten_cells(a_dend), flatten_cells(b_dend)))\n",
    "dends_yz = dends[:,1:]\n",
    "dends_xy = dends[:,:2]\n",
    "print ('Size of dendritic tree:', len(dends_xy))\n",
    "\n",
    "de_tr_yz = kdt(dends_yz)\n",
    "de_tr_xy = kdt(dends_xy)\n",
    "\n",
    "\n",
    "c_rad_pf = 5\n",
    "c_rad_aa = 30\n",
    "\n",
    "# Golgi indices, apical first\n",
    "a_ind = (np.ones((a_dend.shape[1], a_dend.shape[0]))*np.arange(a_dend.shape[0])).T\n",
    "b_ind = (np.ones((b_dend.shape[1], b_dend.shape[0]))*np.arange(b_dend.shape[0])).T\n",
    "gol_ind = np.concatenate((flatten_cells(np.expand_dims(a_ind, axis = 2)), flatten_cells(np.expand_dims(b_ind, axis = 2)))).astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T15:22:33.828677Z",
     "start_time": "2017-11-06T15:22:33.818991Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Sme playing around on the tree\n",
    "aa = de_tr_xy.get_arrays()\n",
    "print (type(aa))\n",
    "print (len(aa))\n",
    "print (len(aa[1]))\n",
    "print (type(aa[1]))\n",
    "ff = de_tr_xy.node_data\n",
    "print (ff)\n",
    "print (len(ff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T14:52:18.555452Z",
     "start_time": "2017-11-06T14:52:04.412998Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res_id_pf = []\n",
    "Gid_pf = dict()\n",
    "\n",
    "for i in range(len(Go_co)):\n",
    "    Gid_pf[i] = []\n",
    "\n",
    "min_z = 200-c_rad_pf # minimal z coordinate to make inquiry reasonable (no parallel fibers possible underneath)\n",
    "    \n",
    "print (len(pf_d))\n",
    "for i, pts in enumerate(pf_d):\n",
    "    warnings.simplefilter('ignore')\n",
    "    ind, = de_tr_yz.query_radius(pts[1,1:], r= c_rad_pf)\n",
    "    ind = ind[np.logical_and(dends[ind,0]<pts[1,0], dends[ind,0]>pts[0,0])]\n",
    "    gi = (np.unique(gol_ind[ind])).astype('int')\n",
    "    for k in gi:\n",
    "        Gid_pf[k].append(i)\n",
    "    res_id_pf.append(gi)\n",
    "print (i)\n",
    "    \n",
    "\n",
    "#took 10 minutes for whole size (simplest version, no filtering of height and stuff)\n",
    "    #res_aa_a.append(np.unique((np.floor(ind/n_pt_aa)).astype('int')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T14:52:42.116706Z",
     "start_time": "2017-11-06T14:52:23.787593Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res_id_aa = []\n",
    "Gid_aa = dict()\n",
    "\n",
    "for i in range(len(Go_co)):\n",
    "    Gid_aa[i] = []\n",
    "\n",
    "min_z = 200-c_rad_aa # minimal z coordinate to make inquiry reasonable (no parallel fibers possible underneath)\n",
    "    \n",
    "for i, pts in enumerate(aa_d):\n",
    "    #if i > 10: break\n",
    "    warnings.simplefilter('ignore')\n",
    "    ind, = de_tr_xy.query_radius(pts[1,:2], r= c_rad_aa)\n",
    "    ind = ind[np.logical_and(dends[ind,2]<pts[1,2], dends[ind,2]>pts[0,2])]\n",
    "    gi = (np.unique(gol_ind[ind])).astype('int')\n",
    "    for k in gi:\n",
    "        Gid_aa[k].append(i)\n",
    "    res_id_aa.append(gi)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stats: 28 Golgi cells (150x100)**\n",
    "- Runtime with just appending Golgi indices to result array: 10.3\n",
    "- When adding indices to Golgi array: 10.9 -> efficient!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D SKL, the other way around\n",
    "Idea: Once the tree is constructed, it is fast to search it.\n",
    "It seems to be better to put the large point cloud in the tree and then query for the points of the small cloud.\n",
    "With a Granule-Golgi cell ratio of 400:1, putting the granule cells in the tree might be the better option. For the parallel fiber, the amount of points queried for the dendrites can be further decreased by not searching for the ones that are only in the granule cell layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T15:02:16.018884Z",
     "start_time": "2017-11-06T15:02:15.817656Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pf_tr = kdt(pf_d[:,0,1:])\n",
    "aa_tr = kdt(aa_d[:,0,:2])\n",
    "# The goal is to search for the points of the upper part of dend_a in the pf_tr tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T15:25:13.847167Z",
     "start_time": "2017-11-06T15:25:13.634693Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "go_gr_pf = [set() for i in range(len(Go_co))]\n",
    "gr_go_pf = [set() for i in range(len(Gr_co))]\n",
    "\n",
    "min_z = 200-c_rad_pf # minimal z coordinate to make inquiry reasonable (no parallel fibers possible underneath)\n",
    "    \n",
    "for i, pt in enumerate(dends):\n",
    "    if pt[0] > min_z:\n",
    "        warnings.simplefilter('ignore')\n",
    "        ind, = pf_tr.query_radius(pt[1:], r= c_rad_pf)\n",
    "        ind = ind[np.logical_and(pf_d[ind,0,0]<pt[0], pf_d[ind,1,0]>pt[0])]\n",
    "        go_gr_pf[int(gol_ind[int(i)])].update(ind.astype('int'))\n",
    "        for k in ind:\n",
    "            gr_go_pf[k].add(gol_ind[i])\n",
    "\n",
    "            \n",
    "print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T15:02:26.797733Z",
     "start_time": "2017-11-06T06:02:18.663Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gr_go_aa = [set() for i in range(len(Gr_co))]\n",
    "go_gr_aa = [set() for i in range(len(Go_co))]\n",
    "\n",
    "for i, pt in enumerate(dends):\n",
    "    warnings.simplefilter('ignore')\n",
    "    ind, = aa_tr.query_radius(pt[:2], r= c_rad_aa)\n",
    "    ind = ind[np.logical_and(aa_d[ind,0,2]<pt[2], aa_d[ind,1,2]>pt[2])]\n",
    "    go_gr_aa[gol_ind[i]].update(ind)\n",
    "    for k in ind:\n",
    "        gr_go_aa[k].add(i)\n",
    "\n",
    "print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T19:49:22.671390Z",
     "start_time": "2017-11-03T19:49:22.661271Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tplt = [(), ()]\n",
    "type(tplt)\n",
    "type (tplt[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T12:13:42.191802Z",
     "start_time": "2017-11-03T12:13:40.561918Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 4\n",
    "# 3d plot\n",
    "pts_1 = Go_co[n:n+2]\n",
    "pts_2 = Gr_co[np.array(Gid_aa[n]),:]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "plot3d(ax, Gr_co, 'k.', markersize=0.2)\n",
    "plot3d(ax, Go_co, 'ro')\n",
    "plot3d(ax, pts_1, 'go')\n",
    "#ax.plot(all_pts[0,0],all_pts[0,1],all_pts[0,2], 'go')\n",
    "plot3d(ax, pts_2, 'b.', markersize=0.4)\n",
    "plt.axis('equal')\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "for i, [j, k, tit] in enumerate([[0,1, 'x-y plane'], [1,2, 'y-z plane'], [0,2, 'x-z plane']]):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.plot(Gr_co[:,j], Gr_co[:,k],  'k.', markersize=0.2)\n",
    "    plt.plot(Go_co[:,j], Go_co[:,k],  'ro')\n",
    "    plt.plot(pts_1[:,j], pts_1[:,k], 'go')\n",
    "    plt.plot(pts_2[:,j], pts_2[:,k], 'b.', markersize=4.0)\n",
    "    plt.axis('equal')\n",
    "    plt.title(tit)\n",
    "    \n",
    "plt.figure(figsize=(15,5))\n",
    "for i, [j, k, tit] in enumerate([[0,1, 'x-y plane'], [1,2, 'y-z plane'], [0,2, 'x-z plane']]):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.plot(Gr_co[:,j], Gr_co[:,k],  'k.', markersize=0.3)\n",
    "    plt.plot(Go_co[:,j], Go_co[:,k],  'ro')\n",
    "    plt.plot(pts_1[:,j], pts_1[:,k], 'go')\n",
    "    plt.plot(pts_2[:,j], pts_2[:,k], 'b.', markersize=2.0)\n",
    "    plt.title(tit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scipy implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-02T10:39:28.212361Z",
     "start_time": "2017-11-02T10:39:27.611098Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import KDTree as kdt2\n",
    "\n",
    "aa_d2 = aa_d.reshape(aa_d.shape[0]*aa_d.shape[1], aa_d.shape[2])\n",
    "\n",
    "def flatten_cells (dat):\n",
    "    return dat.reshape(dat.shape[0]*dat.shape[1],dat.shape[2])\n",
    "\n",
    "\n",
    "kt2 = kdt2(aa_d2)\n",
    "# connection radius\n",
    "c_rad = 30.0\n",
    "n_pt_aa = 5\n",
    "\n",
    "res = []\n",
    "for i, pt in enumerate(flatten_cells(b_dend)):\n",
    "    ind = kt2.query_ball_point(pt, r= c_rad)\n",
    "    ind = np.asarray(ind)\n",
    "    #print (len(ind[0]))\n",
    "    #print (len(np.floor(ind[0]/n_pt_aa)))\n",
    "    res.append((np.floor(ind/n_pt_aa)).astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-01T14:26:44.652002Z",
     "start_time": "2017-11-01T14:26:44.591409Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### deprecated!\n",
    "\n",
    "all_pts = np.zeros((1,3))\n",
    "pt_order = [a_dend, b_dend, aa_d]\n",
    "start_ind = np.zeros(len(pt_order))\n",
    "pts_per_cell = np.zeros(len(pt_order))\n",
    "\n",
    "for i, pts in enumerate(pt_order):    \n",
    "    pts_f = pts.reshape(pts.shape[0]*pts.shape[1], pts.shape[2])\n",
    "    print (pts_f.shape)\n",
    "    start_ind[i] = len(all_pts)-1\n",
    "    pts_per_cell[i] = pts.shape[1]\n",
    "    all_pts = np.concatenate((all_pts, pts_f))\n",
    "all_pts = all_pts[1:,:]\n",
    "\n",
    "print (start_ind)\n",
    "print (pts_per_cell)\n",
    "\n",
    "aa_d2 = aa_d.reshape(aa_d.shape[0]*aa_d.shape[1], aa_d.shape[2])\n",
    "\n",
    "kt = kdt(aa_d2)\n",
    "# connection radius\n",
    "c_rad = 30.0\n",
    "# The index at which the source ids start\n",
    "so_ind_start = int (start_ind[2])\n",
    "# source cells: number of points per cell\n",
    "so_ppc = pts_per_cell [2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Golgi-Golgi Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-08T11:09:55.576722Z",
     "start_time": "2017-11-08T11:09:55.432065Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculate Golgi-to-Golgi distances\n",
    "goc = read_in_coordfile(path_ivan+fns['go_coord'])\n",
    "dis = np.zeros((len(goc), len(goc)))\n",
    "for i in range(len(goc)):\n",
    "    for j in range(i):\n",
    "        dd = np.linalg.norm(goc[i,:] - goc[j,:])\n",
    "        dis[i,j] = dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-08T11:10:00.453768Z",
     "start_time": "2017-11-08T11:10:00.327160Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, array([ 1.5]), array([ 1.25]), array([ 1.125]), array([ 1.0625]), array([ 1.03125]), array([ 1.015625]), array([ 1.0078125]), array([ 1.00390625]), array([ 1.00195312]), array([ 1.00097656]), array([ 1.00048828]), array([ 1.00024414]), array([ 1.00012207]), array([ 1.00006104]), array([ 1.00003052]), array([ 1.00001526]), array([ 1.00000763]), array([ 1.00000381])]\n",
      "At 1/kT =  [ 1.00000381] connection probability radii are:\n",
      "0.5 at radius [ 0.69]\n",
      "0.2 at radius [ 1.61]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Increase or decrease k taking into account previous values         \n",
    "def change_kTi (kTi, kTi_trace, decrease = False):\n",
    "    ''' Increase or decrease the inverse of  '''\n",
    "    ks = np.sort(np.array(kTi_trace))\n",
    "    if decrease: ks = ks[::-1]\n",
    "    if kTi == ks[-1]: return kTi*2\n",
    "    else: return (ks[np.where(ks == kTi)[0]+1]+kTi)/2\n",
    "    \n",
    "#P\n",
    "def rad_prob_stats(kTi, prs = [0.5, 0.2]):\n",
    "    print ('At 1/kT = ', kTi ,'connection probability radii are:')\n",
    "    for pr in prs:\n",
    "        print (pr, 'at radius', np.round(-np.log(pr)/kTi, 2))\n",
    "        \n",
    "goal_range = [9.5, 10.5]\n",
    "n_found = 0\n",
    "kTi = 1 #the inverse of k(Boltzmann constant) and the temperature T\n",
    "kTi_trace = [kTi]\n",
    "edis = np.zeros(dis.shape)\n",
    "while (n_found < goal_range[0] or n_found > goal_range[1]) and len(kTi_trace) < 20:   \n",
    "    edis = np.tril(np.exp(-kTi*dis) - np.eye(len(edis)))\n",
    "    conn = edis > np.random.rand(*edis.shape)\n",
    "    n_found = np.mean(sum(conn))*2\n",
    "    if n_found > goal_range [1]: kTi = change_kTi(kTi, kTi_trace)\n",
    "    elif n_found < goal_range[0]: kTi = change_kTi(kTi, kTi_trace, True)\n",
    "    kTi_trace.append(kTi)\n",
    "    \n",
    "print (kTi_trace)\n",
    "\n",
    "rad_prob_stats(kTi)\n",
    "\n",
    "res = [set() for i in range(len(goc))]        \n",
    "for i in range(len(goc)):\n",
    "    res[i].update(np.where(conn[i,:])[0])\n",
    "    res[i].update(np.where(conn[:,i])[0])\n",
    "    \n",
    "l_res = [len(res[l]) for l in range(len(res))]\n",
    "#print (l_res)\n",
    "print (np.mean(l_res))\n",
    "\n",
    "#print (np.max(edis))\n",
    "\n",
    "\n",
    "#print (edis)\n",
    "\n",
    "#mean_s = np.mean(sum(edis)) #get the average sum\n",
    "\n",
    "#sum of all probabilities to date\n",
    "\n",
    "#pr_edis = edis/mean_s*goal_num\n",
    "#print (goal_num*mean_s)\n",
    "\n",
    "#print (np.max(pr_edis))\n",
    "\n",
    "#sc_f = np.max(pr_edis)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-31T14:12:48.149480Z",
     "start_time": "2017-10-31T14:12:48.127072Z"
    }
   },
   "source": [
    "## Kd-Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Background\n",
    "\n",
    "- binary search stree\n",
    "    - every branching node contains a k-dimensional point\n",
    "    - every leaf node contains a set of points\n",
    "- every branching node represents a splitting hyperplane that divides the space into two half-spaces    \n",
    "    - left of the splitting hyperplane = left subtree, same for richt\n",
    "    - each spliitting hyperplane is perpendicular to one of the axes in the k-dimensional space\n",
    "    - the axes for the splitting hyperplanes are rotating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On the chicken kd-tree library:\n",
    "- works with datastructure POINT3D\n",
    "    - constructor: make-point3d dbl dbl dbl \n",
    "    - accessors point3d-x /y/z\n",
    "    - predicate: point3d?\n",
    "- KD-Tree itself\n",
    "    - constructor: list->kd-tree (list of POINT3D)\n",
    "    - predicates: kd-tree? -> checks object, kd-tree-empty?, \n",
    "        - kd-tree-is-valid? -> checks if all points in subtree lie on left side of hyperplane and right on right\n",
    "        - kd-tree-all-subtrees-are-valid? -> valid property for all branching nodes?\n",
    "    - accessors: \n",
    "        - kd-tree->list  -> all the points contained in tree in a POINT3D list\n",
    "        - kd-tree->list\\* -> list with elements of the form (i . POINT3D) -> i is the relative integer index of the point\n",
    "     \n",
    "for other accessors, the author was not motivated enough to write a description.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Pythonic Kd-Tree libraries:\n",
    "\n",
    "#### Scipy:\n",
    "- Documentation: https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.spatial.KDTree.html\n",
    "- Source Code: https://github.com/scipy/scipy/blob/master/scipy/spatial/kdtree.py\n",
    "- Algorithm reference Maneewongvatana and Mount 1999\n",
    "- Can be queried for r nearest neighbors, however r should be relatively small because elsewise, brute force is just as efficient.\n",
    "- Approximate nearest neighbors seems to be another, and much faster option, and might work well for us.\n",
    "- Uses pythonic libraries. \n",
    "- The heap queue algorithm: https://github.com/python/cpython/blob/2.7/Lib/heapq.py seems to be used, but it is also in python\n",
    "\n",
    "\n",
    "#### SKlearn:\n",
    "- Documentation: http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html\n",
    "- Source Code: https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/neighbors/kd_tree.pyx\n",
    "- uses cython. Might thus be faster. Let's check.\n",
    "\n",
    "\n",
    "Neither of them appears to have parallelization supported right from the beginning.\n",
    "Both just take regular arrays as inputs.\n",
    "\n",
    "\n",
    "Could be interesting:\n",
    "http://ieeexplore.ieee.org/abstract/document/5654017/?reload=true\n",
    "GPU implementation for kNN search\n",
    "Following this:\n",
    "https://link.springer.com/chapter/10.1007/978-3-642-38628-2_67\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import KDTree as T_sp\n",
    "from sklearn.neighbors import KDTree as T_sk\n",
    "s_dat = np.asarray(import_csv(fn_out))\n",
    "import time\n",
    "\n",
    "rn = np.random.randint(0, len(s_dat), 50)\n",
    "nn = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (s_dat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_dist = np.zeros((len(rn), nn))\n",
    "k_ind = np.zeros((len(rn), nn))\n",
    "tk0 = time.time()\n",
    "kt = T_sk(s_dat)\n",
    "tk1 = time.time()\n",
    "for i, ii in enumerate(rn):\n",
    "    warnings.simplefilter('ignore') #definitely not ideal. But no clue how the validation file gets called\n",
    "    k_dist[i,:], k_ind [i,:] = kt.query(s_dat[ii,:], k = nn)\n",
    "tk2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_dist = np.zeros((len(rn), nn))\n",
    "p_ind = np.zeros((len(rn), nn))\n",
    "tp0 = time.time()\n",
    "pt = T_sp(s_dat)\n",
    "tp1 = time.time()\n",
    "for i, ii in enumerate(rn):\n",
    "    p_dist[i,:], p_ind [i,:] = pt.query(s_dat[ii,:], k = nn)\n",
    "tp2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Here is the first, blunt comparison of both algorithms in terms of time:\n",
    "print (tk1-tk0)\n",
    "print (tp1-tp0)\n",
    "\n",
    "print (tk2-tk1)\n",
    "print (tp2-tp1)\n",
    "#Scikit-learn is way faster.\n",
    "\n",
    "#print (np.isclose (k_dist, p_dist))\n",
    "#print (k_ind -p_ind) \n",
    "# Where the indices are not the same it is because the distances are equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reading in, subsampling and storing again the csv files in order to have a smaller dataset at hand that has a similar density anyway.\n",
    "\n",
    "import csv\n",
    "\n",
    "fn_in = 'input_files/GCTcoordinates.dat'\n",
    "fn_out = 'input_files/GCT_small.dat' #100x150 -> 11 k\n",
    "fn_out2 = 'input_files/GCT_smallsmall.dat' #30x100 -> 2.2k\n",
    "fn_out3 = 'input_files/GCT_tiny.dat' # 2x5 ->  6\n",
    "\n",
    "x_r = [0.0, 2.0]\n",
    "y_r = [0.0, 5.0]\n",
    "z_r = [0.0, 1000.0]\n",
    "rrs = [x_r, y_r, z_r]\n",
    "\n",
    "def subsample_coords (rrs, fn_in, fn_out = 'input_files/downsampled.dat', save = True):\n",
    "    res = []\n",
    "    rnr = [0, 0]\n",
    "    with open(fn_in, newline = '') as f, open (fn_out, 'w', newline = '') as w_f:\n",
    "        rr = csv.reader(f, delimiter = ' ')\n",
    "        if save: wr = csv.writer(w_f, delimiter = ' ')\n",
    "        for line in rr:\n",
    "            in_range = all([float(line[i])>rrs[i][0] and float(line[i])<rrs[i][1] for i in range(len(rrs))]) #check if in range\n",
    "            if in_range: \n",
    "                if save: wr.writerow([float(line[j]) for j in range(len(rrs))])\n",
    "                res.append([float(line[j]) for j in range(len(rrs))])\n",
    "                rnr[0] = rnr[0]+1\n",
    "            else:\n",
    "                rnr[1] = rnr[1]+1\n",
    "    print ('Subsampled {} of {}'.format(rnr[0], rnr[1]))\n",
    "    return res\n",
    "\n",
    "#my_s = subsample_coords (rrs, fn_in, fn_out3, save = True)\n",
    "\n",
    "def import_csv (fn):\n",
    "    res = []\n",
    "    with open (fn, newline = '') as f:\n",
    "        rr = csv.reader(f, delimiter = ' ')\n",
    "        for line in rr:\n",
    "            res.append([float(line[j]) for j in range(len(line))])\n",
    "    return np.asarray(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random and deprecated stuff below this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Development site for the read_in_config function.\n",
    "\n",
    "#from neuron import hoc, h\n",
    "# weird thing that I did not get yet: despite all the copy statements, the second time you calculate d_l, it would give 0. \n",
    "# Thus, the hoc objects must somehow take on each other's parameters... \n",
    "\n",
    "#load an empty hoc object and find out which parameters are native to that object (probably useless...)\n",
    "empty_hoc = dir(neuron.hoc.HocObject()).copy()\n",
    "config_fn = './input_files/Parameters.hoc'\n",
    "overwrite_config =  True\n",
    "#load our own hoc object from the parameter file, get the disjunct list of parameters (probably useless...)\n",
    "neuron.h.xopen(config_fn)\n",
    "full_hoc = dir(neuron.h)\n",
    "if 'd_l' not in globals():\n",
    "    d_l = list (set (full_hoc)  - set (empty_hoc)).copy()\n",
    "\n",
    "#c_d = b.config_dict\n",
    "c_d = dict((v,k) for k,v in b.config_dict.items()) #exchange key and value\n",
    "#this dict translates the parameters used in the Parameters file to the ones used in the code\n",
    "# Check if the Brep object contains the right parameters and if so, change them.\n",
    "# Note: Resolve conflicts with the command line - I think default should be that command line should has priority \n",
    "self = b\n",
    "for h_k in full_hoc:\n",
    "    if h_k in c_d.keys() and h_k not in self.cl_args.keys():\n",
    "        if hasattr (self.args, c_d[h_k]):\n",
    "            setattr (self.args, c_d[h_k], getattr (neuron.h, h_k))\n",
    "        else:\n",
    "            print ('Did not find {}'.format(c_d[h_k]))\n",
    "    elif h_k in c_d.keys() and h_k in self.cl_args.keys():\n",
    "        if hasattr (self.args, c_d[h_k]):\n",
    "            if overwrite_config:\n",
    "                warnings.warn('Parameter {} was set both by command line and in config, will use value from command line'.format(c_d[h_k]))\n",
    "            else:\n",
    "                warnings.warn('Parameter {} was set both by command line and in config, will use value from config file'.format(c_d[h_k]))\n",
    "                setattr (self.args, c_d[h_k], getattr (neuron.h, h_k))\n",
    "    \n",
    "# The following two parameters are an exception:\n",
    "if 'GLdepth' in d_l and 'PCLdepth' in d_l and not 'aa-length' in self.cl_args.keys():\n",
    "    setattr (self.args, 'aa-length', getattr(neuron.h, 'GLdepth')+getattr(neuron.h,'PCLdepth'))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### The transformations of the parameters, automized in a small parser script.\n",
    "\n",
    "#Had to be done only once, but will be kept for reference.\n",
    "\n",
    "from neuron import hoc, h\n",
    "# weird thing that I did not get yet: despite all the copy statements, the second time you calculate d_l, it would give 0. \n",
    "# Thus, the hoc objects must somehow take on each other's parameters... \n",
    "\n",
    "#load an empty hoc object and find out which parameters are native to that object (probably useless...)\n",
    "empty_hoc = dir(hoc.HocObject()).copy()\n",
    "config_fn = './input_files/Parameters.hoc'\n",
    "#load our own hoc object from the parameter file, get the disjunct list of parameters (probably useless...)\n",
    "h.xopen(config_fn)\n",
    "full_hoc = dir(h).copy()\n",
    "if 'd_l' not in globals():\n",
    "    d_l = list (set (full_hoc)  - set (empty_hoc)).copy()\n",
    "\n",
    "# Code file\n",
    "tf = 'brep_commented.scm'\n",
    "# Step one: parse all lines that contain both config or options as those are the ones that \n",
    "res_dict = {}\n",
    "with open (tf, 'rb') as tff:\n",
    "    for line in tff:\n",
    "        st = str(line)\n",
    "        c = st.find (\"config '\")\n",
    "        o = st.find (\"options '\") \n",
    "        if c > 0 and o > 0:\n",
    "            c_clb = st[c:].find (')')\n",
    "            o_clb = st[o:].find (')')\n",
    "            res_dict[st[c+8:c+c_clb]] = st[o+9:o+o_clb] \n",
    "    tff.close()\n",
    "\n",
    "#parameters that are defined in the res file but have not been parsed yet\n",
    "rest_hk = (set (d_l)- set(res_dict.keys()))\n",
    "rem = {}\n",
    "#check if they occur in the code\n",
    "with open ('brep_commented.scm', 'rb') as f_in:\n",
    "    n = 0\n",
    "    for line in f_in:\n",
    "        n = n+1\n",
    "        for w in rest_hk:\n",
    "            if str(line).find(w)>0:\n",
    "                if w in rem.keys():\n",
    "                    rem[w].append(n)\n",
    "                else:\n",
    "                    rem[w] = [n]                  \n",
    "print (rem) # 'TS is coincidental, the other two parameters are taken seperate care of.\n",
    "\n",
    "#print the resulting dict to a file.\n",
    "with open ('par_d2.txt', 'w') as f_out:\n",
    "    for k in res_dict.keys():\n",
    "        f_out.write(\"'\" +res_dict[k]+ \"' : '\"+k+ \"', \\n\" )\n",
    "\n",
    "#print (res_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Used this to try out command line calls. \n",
    "\n",
    "#Brep = importlib.reload(BREPpy)\n",
    "#stupid workaround so that the known command line call can be kept up.\n",
    "#I think I changed something, would have to git checkout....\n",
    "class Brep2 (Brep, b):\n",
    "    def __init__:\n",
    "        self.args = b.args\n",
    "        self.config_dict = b.config_dict\n",
    "        self.cl_args = b.cl_args\n",
    "        \n",
    "\n",
    "\n",
    "def new_Brep (arg_dict = {}, **kwargs):\n",
    "    if True: #delete and make new Brep file\n",
    "        ! python ~/Desktop/LabRot_OIST/pybrep/BREPpy.py --config_file blabla \n",
    "        a = pkl.load(open('./tmp.pkl', 'rb'))\n",
    "        ! rm tmp.pkl\n",
    "        b = Brep2(a)\n",
    "    else: b = Brep2(pkl.load(open('./tmp.pkl', 'rb'))) \n",
    "    #Process and add arguments    \n",
    "    arg_dict.update(kwargs)\n",
    "    for k in arg_dict.keys():\n",
    "        if hasattr (b.args, k):\n",
    "            setattr (b.args, k, arg_dict[k])\n",
    "        else:\n",
    "            warnings.warn ('Keyline argument {} not known'.format(k))\n",
    "            \n",
    "    return b\n",
    "\n",
    "arg_dict = {'config_file': 'blabla.c',\n",
    "            'verbose': True}\n",
    "b = new_Brep(arg_dict, gc_points_fn = 'yipyip' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Fun with magic\n",
    "\n",
    "# http://ipython.readthedocs.io/en/stable/interactive/magics.html\n",
    "#notable ones\n",
    "# %debug #-> debug stuff. Lets you inspect the stack frame of an exception interactively\n",
    "# %env #-> see all env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-31T14:27:47.660245Z",
     "start_time": "2017-10-31T14:27:47.511968Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Used this to develop the soma rendering algorithm\n",
    "\n",
    "dat = Gr_co\n",
    "\n",
    "print (dat.shape)\n",
    "\n",
    "lower = dat.T.ravel()\n",
    "upper = -(dat-[Gc_x, Gc_y, Gc_z]).T.ravel()\n",
    "most_out_idx = np.mod(np.argsort(np.concatenate((lower,upper))), len(dat))\n",
    "\n",
    "n_del = 500\n",
    "dat = dat[np.setdiff1d(np.arange(len(dat)), most_out_idx[:n_del]),:]\n",
    "\n",
    "print (dat.shape)\n",
    "\n",
    "test_ar = np.array([[0,1,3],[-1,3,5],[2,3,4], [5,3,2]])\n",
    "print (test_ar.ravel())\n",
    "print (np.argsort(test_ar.T.ravel()))\n",
    "tt2 = test_ar- [1,2,3]\n",
    "print (tt2)\n",
    "\n",
    "print ('')\n",
    "most_out = np.argsort(np.concatenate(( test_ar.T.ravel(), -(test_ar-[1,2,3]).T.ravel() )))\n",
    "\n",
    "most_out_idx = np.mod(most_out, len(test_ar))\n",
    "\n",
    "print (len(test_ar))\n",
    "print( -(test_ar-[1,2,3]))\n",
    "print( -(test_ar-[1,2,3]).ravel())\n",
    "print (np.argsort( -(test_ar-[1,2,3]).ravel()))\n",
    "\n",
    "print ('')\n",
    "print (np.concatenate(( test_ar.ravel(), -(test_ar-[1,2,3]).ravel() )))\n",
    "print (most_out)\n",
    "print (most_out_idx)\n",
    "print \n",
    "\n",
    "print ('')\n",
    "print (test_ar)\n",
    "print( -(test_ar-[1,2,3]))\n",
    "#hs = np.sum(np.heaviside(-dat) + np.heaviside(dat-[Gc_x, Gx_y, Gc_z]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(332**2 + 100**2)**0.5 / 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(6**2+60**2)**0.5/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "799px",
    "left": "0px",
    "right": "1262.9px",
    "top": "108px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
