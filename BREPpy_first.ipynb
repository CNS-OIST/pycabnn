{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook\n",
    "\n",
    "Note: installing neuron was not that straightforward.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pickle \n",
    "import warnings\n",
    "import neuron\n",
    "import sys\n",
    "import csv\n",
    "#! echo $PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run BREPpy.py\n",
    "\n",
    "#Todo: Read in from command line for int or bool parameters.\n",
    "b = Brep()\n",
    "b.init_from_script(['--config_fn','./input_files/Parameters.hoc'])\n",
    "b.read_in_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the Parameter file\n",
    "Not nice: there are about 4 different names for one variable- there are the default ones in the code, the assigned ones in the code, and the ones in the parameter file. \n",
    "I will use variables that are similar to the ones defined in the grammar in the code, with the difference that they will be adapted to Python syntax ( _ instead of -), and a few have an additional postfix to clarify what they do (e.g. \\_fn = filename) \n",
    "\n",
    "\n",
    "### On the installation of neuron\n",
    "Neuron did not really work out of the box for me. \n",
    "I (ubuntu 16.04 LTS, 64 bit) did it the following way:\n",
    "- Download the .rpm package from here: https://www.neuron.yale.edu/neuron/download\n",
    "- Install it with: \n",
    "    `alien -i nrn_...*package*` (Note that the .deb package did not work out, and neither did the installation using rpm directly)\n",
    "- Edit the .bashrc file by adding the following lines: \n",
    "\n",
    "    `#Added for neuron\n",
    "    export PYTHONPATH=\"${PYTHONPATH}:/usr/local/nrn/lib/python/\" `\n",
    "    \n",
    "    (first check that this path is actually where it got installed by going to the folder and see whether `python -c 'import neuron'` tells you about your NEURON version or whether there ain't no module called neuron.\n",
    "\n",
    "\n",
    "http://www.davison.webfactional.com/notes/hoc-to-python-bulbnet/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Checking out the output of the original BREP program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#filenames and input paths for the different files.\n",
    "import os\n",
    "res_p = os.path.normpath(os.getcwd()+'/output_1/')\n",
    "\n",
    "fns = {'aa_gol_dist':'AAtoGoCdistances.dat',\n",
    "'aa_gol_dist':'AAtoGoCsegments.dat',\n",
    "'aa_gol_source':'AAtoGoCsources.dat',\n",
    "'aa_gol_target':'AAtoGoCtargets.dat',\n",
    "'gran_coord': 'GCcoordinates.sorted.dat',\n",
    "'gran_t_coord':'GCTcoordinates.sorted.dat',\n",
    "'go_dist':'GoCadendcoordinates.sorted.dat',\n",
    "'go_axon_coord':'GoCaxoncoordinates.sorted.dat',\n",
    "'go_basd_coord':'GoCbdendcoordinates.sorted.dat',\n",
    "'go_coord':'GoCcoordinates.sorted.dat',\n",
    "'go_dist':'GoCdistances.dat',\n",
    "'go_go_gap_dist':'GoCtoGoCgapdistances.dat',\n",
    "'go_go_gap_source':'GoCtoGoCgapsources.dat',\n",
    "'go_go_gap_target':'GoCtoGoCgaptargets.dat',\n",
    "'go_go_dist':'GoCtoGoCdistances.dat',\n",
    "'go_go_sources':'GoCtoGoCsources.dat',\n",
    "'go_go_targets':'GoCtoGoCtargets.dat',\n",
    "'pf_go_dist':'PFtoGoCdistances.dat',\n",
    "'pf_go_seg':'PFtoGoCsegments.dat',\n",
    "'pf_go_source':'PFtoGoCsources.dat',\n",
    "'pf_go_target':'PFtoGoCtargets.dat'}\n",
    "\n",
    "#a = import_csv(in_f)\n",
    "#rr = read_in_coordfile (in_goba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#def import_csv (fn):\n",
    "def read_in_coordfile (fn):\n",
    "    res = []\n",
    "    with open (fn, newline = '') as f:\n",
    "        rr = csv.reader(f, delimiter = ' ')\n",
    "        err = []\n",
    "        for line in rr:\n",
    "            ar = []\n",
    "            for j in range(len(line)):\n",
    "                try: ar.append(float(line[j]))\n",
    "                except: err.append(line[j])\n",
    "            res.append(np.asarray(ar))\n",
    "    if len(err)> 0: print ('Could not parse on {} instances: {}'.format(len(err), set(err)))\n",
    "    return np.asarray(res)\n",
    "\n",
    "#rr = read_in_coordfile(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in file {}: GoCtoGoCtargets.dat\n",
      "Shape is {} (28971, 1)\n",
      "Could not parse on 200 instances: {''}\n",
      "Read in file {}: GoCaxoncoordinates.sorted.dat\n",
      "Shape is {} (200, 120)\n",
      "Could not parse on 200 instances: {''}\n",
      "Read in file {}: GoCbdendcoordinates.sorted.dat\n",
      "Shape is {} (200, 72)\n",
      "Read in file {}: GCcoordinates.sorted.dat\n",
      "Shape is {} (10000, 3)\n",
      "Read in file {}: PFtoGoCtargets.dat\n",
      "Shape is {} (42, 1)\n",
      "Read in file {}: GoCcoordinates.sorted.dat\n",
      "Shape is {} (200, 3)\n",
      "Read in file {}: GCTcoordinates.sorted.dat\n",
      "Shape is {} (6, 3)\n",
      "Read in file {}: AAtoGoCtargets.dat\n",
      "Shape is {} (6710504, 1)\n",
      "Read in file {}: PFtoGoCsources.dat\n",
      "Shape is {} (42, 1)\n",
      "Read in file {}: AAtoGoCsources.dat\n",
      "Shape is {} (6710504, 1)\n",
      "Read in file {}: PFtoGoCdistances.dat\n",
      "Shape is {} (42, 1)\n",
      "Read in file {}: GoCtoGoCgapsources.dat\n",
      "Shape is {} (25580, 1)\n",
      "Read in file {}: GoCdistances.dat\n",
      "Shape is {} (39800, 3)\n",
      "Read in file {}: GoCtoGoCdistances.dat\n",
      "Shape is {} (28971, 1)\n",
      "Read in file {}: PFtoGoCsegments.dat\n",
      "Shape is {} (42, 2)\n",
      "Read in file {}: GoCtoGoCgaptargets.dat\n",
      "Shape is {} (25580, 1)\n",
      "Read in file {}: GoCtoGoCgapdistances.dat\n",
      "Shape is {} (25580, 1)\n",
      "Read in file {}: AAtoGoCsegments.dat\n",
      "Shape is {} (6710504, 2)\n",
      "Read in file {}: GoCtoGoCsources.dat\n",
      "Shape is {} (28971, 1)\n"
     ]
    }
   ],
   "source": [
    "for k, v in fns.items():\n",
    "    print ('Read in file: ', v)\n",
    "    c_p = os.path.normpath(res_p+'/'+v)\n",
    "    cur = read_in_coordfile(c_p)\n",
    "    print ('Shape is: ', cur.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 72)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 72 into shape (50,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-132-f6a7f8def76f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 72 into shape (50,3)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f44c06282b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print (rr.shape)\n",
    "ri = rr[:,0]\n",
    "ro = rr[0,:]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "for j in range(3):\n",
    "    plt.figure()\n",
    "    for i in range(len(rr)):\n",
    "        g = rr[i,:].reshape([50,3])\n",
    "        plt.plot(g[:25,j])\n",
    "        plt.plot(g[25:,j])\n",
    "        \n",
    "plt.figure()\n",
    "for i in range(len(rr)):\n",
    "    g = rr[i,:].reshape([50,3])\n",
    "    plt.plot(g[24,0], g[24,1], 'kx')\n",
    "    plt.plot(g[49,0], g[49,1], 'rx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Checking out the kd-tree libraries\n",
    "\n",
    "Scipy:\n",
    "- Documentation: https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.spatial.KDTree.html\n",
    "- Source Code: https://github.com/scipy/scipy/blob/master/scipy/spatial/kdtree.py\n",
    "- Algorithm reference Maneewongvatana and Mount 1999\n",
    "- Can be queried for r nearest neighbors, however r should be relatively small because elsewise, brute force is just as efficient.\n",
    "- Approximate nearest neighbors seems to be another, and much faster option, and might work well for us.\n",
    "- Uses pythonic libraries. \n",
    "- The heap queue algorithm: https://github.com/python/cpython/blob/2.7/Lib/heapq.py seems to be used, but it is also in python\n",
    "\n",
    "\n",
    "SKlearn:\n",
    "- Documentation: http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html\n",
    "- Source Code: https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/neighbors/kd_tree.pyx\n",
    "- uses cython. Might thus be faster. Let's check.\n",
    "\n",
    "\n",
    "Neither of them appears to have parallelization supported right from the beginning.\n",
    "Both just take regular arrays as inputs.\n",
    "\n",
    "\n",
    "Could be interesting:\n",
    "http://ieeexplore.ieee.org/abstract/document/5654017/?reload=true\n",
    "GPU implementation for kNN search\n",
    "Following this:\n",
    "https://link.springer.com/chapter/10.1007/978-3-642-38628-2_67\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import KDTree as T_sp\n",
    "from sklearn.neighbors import KDTree as T_sk\n",
    "s_dat = np.asarray(import_csv(fn_out))\n",
    "import time\n",
    "\n",
    "rn = np.random.randint(0, len(s_dat), 50)\n",
    "nn = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(798000, 3)\n"
     ]
    }
   ],
   "source": [
    "print (s_dat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_dist = np.zeros((len(rn), nn))\n",
    "k_ind = np.zeros((len(rn), nn))\n",
    "tk0 = time.time()\n",
    "kt = T_sk(s_dat)\n",
    "tk1 = time.time()\n",
    "for i, ii in enumerate(rn):\n",
    "    warnings.simplefilter('ignore') #definitely not ideal. But no clue how the validation file gets called\n",
    "    k_dist[i,:], k_ind [i,:] = kt.query(s_dat[ii,:], k = nn)\n",
    "tk2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_dist = np.zeros((len(rn), nn))\n",
    "p_ind = np.zeros((len(rn), nn))\n",
    "tp0 = time.time()\n",
    "pt = T_sp(s_dat)\n",
    "tp1 = time.time()\n",
    "for i, ii in enumerate(rn):\n",
    "    p_dist[i,:], p_ind [i,:] = pt.query(s_dat[ii,:], k = nn)\n",
    "tp2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.112079381942749\n",
      "4.108412981033325\n",
      "0.004629611968994141\n",
      "0.04588818550109863\n"
     ]
    }
   ],
   "source": [
    "#Here is the first, blunt comparison of both algorithms in terms of time:\n",
    "print (tk1-tk0)\n",
    "print (tp1-tp0)\n",
    "\n",
    "print (tk2-tk1)\n",
    "print (tp2-tp1)\n",
    "#Scikit-learn is way faster.\n",
    "\n",
    "#print (np.isclose (k_dist, p_dist))\n",
    "#print (k_ind -p_ind) \n",
    "# Where the indices are not the same it is because the distances are equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reading in, subsampling and storing again the csv files in order to have a smaller dataset at hand that has a similar density anyway.\n",
    "\n",
    "import csv\n",
    "\n",
    "fn_in = 'input_files/GCTcoordinates.dat'\n",
    "fn_out = 'input_files/GCT_small.dat' #100x150 -> 11 k\n",
    "fn_out2 = 'input_files/GCT_smallsmall.dat' #30x100 -> 2.2k\n",
    "fn_out3 = 'input_files/GCT_tiny.dat' # 2x5 ->  6\n",
    "\n",
    "x_r = [0.0, 2.0]\n",
    "y_r = [0.0, 5.0]\n",
    "z_r = [0.0, 1000.0]\n",
    "rrs = [x_r, y_r, z_r]\n",
    "\n",
    "def subsample_coords (rrs, fn_in, fn_out = 'input_files/downsampled.dat', save = True):\n",
    "    res = []\n",
    "    rnr = [0, 0]\n",
    "    with open(fn_in, newline = '') as f, open (fn_out, 'w', newline = '') as w_f:\n",
    "        rr = csv.reader(f, delimiter = ' ')\n",
    "        if save: wr = csv.writer(w_f, delimiter = ' ')\n",
    "        for line in rr:\n",
    "            in_range = all([float(line[i])>rrs[i][0] and float(line[i])<rrs[i][1] for i in range(len(rrs))]) #check if in range\n",
    "            if in_range: \n",
    "                if save: wr.writerow([float(line[j]) for j in range(len(rrs))])\n",
    "                res.append([float(line[j]) for j in range(len(rrs))])\n",
    "                rnr[0] = rnr[0]+1\n",
    "            else:\n",
    "                rnr[1] = rnr[1]+1\n",
    "    print ('Subsampled {} of {}'.format(rnr[0], rnr[1]))\n",
    "    return res\n",
    "\n",
    "#my_s = subsample_coords (rrs, fn_in, fn_out3, save = True)\n",
    "\n",
    "def import_csv (fn):\n",
    "    res = []\n",
    "    with open (fn, newline = '') as f:\n",
    "        rr = csv.reader(f, delimiter = ' ')\n",
    "        for line in rr:\n",
    "            res.append([float(line[j]) for j in range(len(line))])\n",
    "    return np.asarray(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random and deprecated stuff below this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nseg for APical is 5 and Basal is 3\n",
      "\t36 \n"
     ]
    }
   ],
   "source": [
    "# Development site for the read_in_config function.\n",
    "\n",
    "#from neuron import hoc, h\n",
    "# weird thing that I did not get yet: despite all the copy statements, the second time you calculate d_l, it would give 0. \n",
    "# Thus, the hoc objects must somehow take on each other's parameters... \n",
    "\n",
    "#load an empty hoc object and find out which parameters are native to that object (probably useless...)\n",
    "empty_hoc = dir(neuron.hoc.HocObject()).copy()\n",
    "config_fn = './input_files/Parameters.hoc'\n",
    "overwrite_config =  True\n",
    "#load our own hoc object from the parameter file, get the disjunct list of parameters (probably useless...)\n",
    "neuron.h.xopen(config_fn)\n",
    "full_hoc = dir(neuron.h)\n",
    "if 'd_l' not in globals():\n",
    "    d_l = list (set (full_hoc)  - set (empty_hoc)).copy()\n",
    "\n",
    "#c_d = b.config_dict\n",
    "c_d = dict((v,k) for k,v in b.config_dict.items()) #exchange key and value\n",
    "#this dict translates the parameters used in the Parameters file to the ones used in the code\n",
    "# Check if the Brep object contains the right parameters and if so, change them.\n",
    "# Note: Resolve conflicts with the command line - I think default should be that command line should has priority \n",
    "self = b\n",
    "for h_k in full_hoc:\n",
    "    if h_k in c_d.keys() and h_k not in self.cl_args.keys():\n",
    "        if hasattr (self.args, c_d[h_k]):\n",
    "            setattr (self.args, c_d[h_k], getattr (neuron.h, h_k))\n",
    "        else:\n",
    "            print ('Did not find {}'.format(c_d[h_k]))\n",
    "    elif h_k in c_d.keys() and h_k in self.cl_args.keys():\n",
    "        if hasattr (self.args, c_d[h_k]):\n",
    "            if overwrite_config:\n",
    "                warnings.warn('Parameter {} was set both by command line and in config, will use value from command line'.format(c_d[h_k]))\n",
    "            else:\n",
    "                warnings.warn('Parameter {} was set both by command line and in config, will use value from config file'.format(c_d[h_k]))\n",
    "                setattr (self.args, c_d[h_k], getattr (neuron.h, h_k))\n",
    "    \n",
    "# The following two parameters are an exception:\n",
    "if 'GLdepth' in d_l and 'PCLdepth' in d_l and not 'aa-length' in self.cl_args.keys():\n",
    "    setattr (self.args, 'aa-length', getattr(neuron.h, 'GLdepth')+getattr(neuron.h,'PCLdepth'))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'neuron'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-673f2528413f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#Had to be done only once, but will be kept for reference.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mneuron\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m# weird thing that I did not get yet: despite all the copy statements, the second time you calculate d_l, it would give 0.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Thus, the hoc objects must somehow take on each other's parameters...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'neuron'"
     ]
    }
   ],
   "source": [
    "### The transformations of the parameters, automized in a small parser script.\n",
    "\n",
    "#Had to be done only once, but will be kept for reference.\n",
    "\n",
    "from neuron import hoc, h\n",
    "# weird thing that I did not get yet: despite all the copy statements, the second time you calculate d_l, it would give 0. \n",
    "# Thus, the hoc objects must somehow take on each other's parameters... \n",
    "\n",
    "#load an empty hoc object and find out which parameters are native to that object (probably useless...)\n",
    "empty_hoc = dir(hoc.HocObject()).copy()\n",
    "config_fn = './input_files/Parameters.hoc'\n",
    "#load our own hoc object from the parameter file, get the disjunct list of parameters (probably useless...)\n",
    "h.xopen(config_fn)\n",
    "full_hoc = dir(h).copy()\n",
    "if 'd_l' not in globals():\n",
    "    d_l = list (set (full_hoc)  - set (empty_hoc)).copy()\n",
    "\n",
    "# Code file\n",
    "tf = 'brep_commented.scm'\n",
    "# Step one: parse all lines that contain both config or options as those are the ones that \n",
    "res_dict = {}\n",
    "with open (tf, 'rb') as tff:\n",
    "    for line in tff:\n",
    "        st = str(line)\n",
    "        c = st.find (\"config '\")\n",
    "        o = st.find (\"options '\") \n",
    "        if c > 0 and o > 0:\n",
    "            c_clb = st[c:].find (')')\n",
    "            o_clb = st[o:].find (')')\n",
    "            res_dict[st[c+8:c+c_clb]] = st[o+9:o+o_clb] \n",
    "    tff.close()\n",
    "\n",
    "#parameters that are defined in the res file but have not been parsed yet\n",
    "rest_hk = (set (d_l)- set(res_dict.keys()))\n",
    "rem = {}\n",
    "#check if they occur in the code\n",
    "with open ('brep_commented.scm', 'rb') as f_in:\n",
    "    n = 0\n",
    "    for line in f_in:\n",
    "        n = n+1\n",
    "        for w in rest_hk:\n",
    "            if str(line).find(w)>0:\n",
    "                if w in rem.keys():\n",
    "                    rem[w].append(n)\n",
    "                else:\n",
    "                    rem[w] = [n]                  \n",
    "print (rem) # 'TS is coincidental, the other two parameters are taken seperate care of.\n",
    "\n",
    "#print the resulting dict to a file.\n",
    "with open ('par_d2.txt', 'w') as f_out:\n",
    "    for k in res_dict.keys():\n",
    "        f_out.write(\"'\" +res_dict[k]+ \"' : '\"+k+ \"', \\n\" )\n",
    "\n",
    "#print (res_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/ines/Desktop/LabRot_OIST/pybrep/BREPpy.py\", line 134, in <module>\r\n",
      "    Brep().initialize_and_dump()\r\n",
      "  File \"/home/ines/Desktop/LabRot_OIST/pybrep/BREPpy.py\", line 123, in initialize_and_dump\r\n",
      "    self.cl_args = self.parser.convert_arg_line_to_args()\r\n",
      "TypeError: convert_arg_line_to_args() missing 1 required positional argument: 'arg_line'\r\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './tmp.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-c22c446b07d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m arg_dict = {'config_file': 'blabla.c',\n\u001b[0;32m     23\u001b[0m             'verbose': True}\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_Brep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_points_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'yipyip'\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-c22c446b07d9>\u001b[0m in \u001b[0;36mnew_Brep\u001b[1;34m(arg_dict, **kwargs)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#delete and make new Brep file\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' python ~/Desktop/LabRot_OIST/pybrep/BREPpy.py --config_file blabla '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpkl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./tmp.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' rm tmp.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBrep2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './tmp.pkl'"
     ]
    }
   ],
   "source": [
    "#Used this to try out command line calls. \n",
    "\n",
    "#Brep = importlib.reload(BREPpy)\n",
    "#stupid workaround so that the known command line call can be kept up.\n",
    "#I think I changed something, would have to git checkout....\n",
    "class Brep2 (Brep, b):\n",
    "    def __init__:\n",
    "        self.args = b.args\n",
    "        self.config_dict = b.config_dict\n",
    "        self.cl_args = b.cl_args\n",
    "        \n",
    "\n",
    "\n",
    "def new_Brep (arg_dict = {}, **kwargs):\n",
    "    if True: #delete and make new Brep file\n",
    "        ! python ~/Desktop/LabRot_OIST/pybrep/BREPpy.py --config_file blabla \n",
    "        a = pkl.load(open('./tmp.pkl', 'rb'))\n",
    "        ! rm tmp.pkl\n",
    "        b = Brep2(a)\n",
    "    else: b = Brep2(pkl.load(open('./tmp.pkl', 'rb'))) \n",
    "    #Process and add arguments    \n",
    "    arg_dict.update(kwargs)\n",
    "    for k in arg_dict.keys():\n",
    "        if hasattr (b.args, k):\n",
    "            setattr (b.args, k, arg_dict[k])\n",
    "        else:\n",
    "            warnings.warn ('Keyline argument {} not known'.format(k))\n",
    "            \n",
    "    return b\n",
    "\n",
    "arg_dict = {'config_file': 'blabla.c',\n",
    "            'verbose': True}\n",
    "b = new_Brep(arg_dict, gc_points_fn = 'yipyip' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print' (<ipython-input-52-e95a52b59324>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-52-e95a52b59324>\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    print 'nb'\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m Missing parentheses in call to 'print'\n"
     ]
    }
   ],
   "source": [
    "## Fun with magic\n",
    "\n",
    "# http://ipython.readthedocs.io/en/stable/interactive/magics.html\n",
    "#notable ones\n",
    "# %debug #-> debug stuff. Lets you inspect the stack frame of an exception interactively\n",
    "# %env #-> see all env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "convert_arg_line_to_args() missing 1 required positional argument: 'arg_line'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ines/Desktop/LabRot_OIST/pybrep/BREPpy.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m         \u001b[0mBrep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize_and_dump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/ines/Desktop/LabRot_OIST/pybrep/BREPpy.py\u001b[0m in \u001b[0;36minitialize_and_dump\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'I'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcl_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_arg_line_to_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m         \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'yoo I parsed it'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: convert_arg_line_to_args() missing 1 required positional argument: 'arg_line'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
